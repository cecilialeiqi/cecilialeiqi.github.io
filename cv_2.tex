%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Medium Length Graduate Curriculum Vitae
% LaTeX Template
% Version 1.1 (9/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Rensselaer Polytechnic Institute (http://www.rpi.edu/dept/arc/training/latex/resumes/)
%
% Important note:
% This template requires the res.cls file to be in the same directory as the
% .tex file. The res.cls file provides the resume style used for structuring the
% document.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[margin, 10pt]{res} % Use the res.cls style, the font size can be changed to 11pt or 12pt here
\usepackage{hyperref}

\usepackage{helvet} % Default font is the helvetica postscript font
%\usepackage{newcent} % To change the default font to the new century schoolbook postscript font uncomment this line and comment the one above
\usepackage{enumitem}
\usepackage{url}
\usepackage{comment}
\setlength{\textwidth}{5.1in} % Text width of the document

\begin{document}

%----------------------------------------------------------------------------------------
%	NAME AND ADDRESS SECTION
%----------------------------------------------------------------------------------------

\moveleft.5\hoffset\centerline{\large\bf Lei, Qi} % Your name at the top
 
\moveleft\hoffset\vbox{\hrule width\resumewidth height 1pt}\smallskip % Horizontal line after name; adjust line thickness by changing the '1pt'
 
\moveleft.5\hoffset\centerline{Website: \url{https://cecilialeiqi.github.io/}}
\moveleft.5\hoffset\centerline{Google Scholar: \url{https://scholar.google.com/citations?user=kGOgaowAAAAJ&hl=en}}
\moveleft.5\hoffset\centerline{Email: \url{qilei@princeton.edu}}
%----------------------------------------------------------------------------------------

\begin{resume}

%----------------------------------------------------------------------------------------
%	OBJECTIVE SECTION
%----------------------------------------------------------------------------------------
 
%\section{RESEARCH\\ INTERESTS}  
%\textbf{Machine Learning:} Provable, efficient and robust algorithms for 
%fundamental machine learning problems, distributed and parallel learning, 
%min-max optimizations with applications to generative adversarial networks and adversarial training

%\textbf{Large-Scale Optimization:} Novel algorithms that exploit 
%the underlying problem structure and are scalable to massive data sets

%\textbf{Deep Learning:} 


%My research interests mainly focus on machine learning, numerical optimization and their applications, such as matrix completion and recommendation system.
%To obtain a career that will allow myself to take full advantage of my passion and experience in software engineering and computer science. 

%----------------------------------------------------------------------------------------
%	EDUCATION SECTION
%----------------------------------------------------------------------------------------

\section{EMPLOYMENT}
  {\sl Princeton University, NJ, United States} \hfill July 2020 - Present
  \begin{itemize}
    \item {\sl Postdoc Research Associate (CIFellow), Electrical Engineering Department }
    \item Postdoc Mentor: Jason D. Lee
  \end{itemize}


\section{EDUCATION}
{\sl University of Texas at Austin, TX, United States} \hfill August 2014 - May 2020
\begin{itemize}
\item {\sl Ph.D., Oden Institute for Computational Sciences and Engineering} 
\item Advisors: Inderjit S. Dhillon and Alexandros 
  G. Dimakis  
\end{itemize} 



{\sl Zhejiang University, Zhejiang, China} \hfill Sep 2010 - June 2014 \begin{itemize}
  \item {\sl B.S., School of Mathematics (with honors)}, Chu Kochen Honors (GPA 3.92/4.0, rank $1^{st}$)
  \item Advisor: Qunsheng Peng, State Key Lab of CAD\&CG.
%\item[--] Related courses: Computer Graphics, Discrete Mathematics, Combinatorics, Object-Oriented Programming, Lab\& Fundamentals of C Programming, Scientific Computing, Fundamentals of Logic and Computer Design
\end{itemize}

\section{AWARDS and RECOGNITIONS}\begin{itemize}[noitemsep]
\item {Computing Innovation Fellowship}\\ \hspace*\fill\hfill{Computing Research Assiciation, 2020-2022}
\item {Simons-Berkeley Research Fellowship} \hspace*\fill\hfill{Simons Institute, 2019 summer}
\item { The National Initiative for Modeling and Simulation Research 
  Fellowship}\\  \hspace*\fill\hfill{UT Austin, 2014-2018}
\item {Rising Star for EECS} \hspace*\fill\hfill{UIUC, 2019}
\item {Rising Star for Computational and Data Science} \hspace*\fill\hfill{UT Austin, 2020}
\item {Gold medal ($5^{th}$ place) in China Girls Math Olympiad (CGMO, an international competition with a proof-based format similar to the International Math Olympiad)} \hfill{China, 2009}
\item {Meritorious Winner (First Prize) for The Mathematical Contest in Modeling (MCM) }
\hspace*\fill{COMAP, 2014}
\item {The Excellence Scholarship(top honor)} \hfill{Zhejing Univ, 2014}
\item {First Prize for CMC (the Mathematics competition of Chinese College Student)} \hspace*\fill\hfill{China, 2012}
%\item {First Prize Scholarship \& Merit Student} \hfill{Zhejiang Univ, 2010-2014}
%\item {Third Prize for ACM Programming Contest} \hfill{Zhejiang Univ, 2012}
\item {First Prize for National Olympiad in Informatics in Provinces (NOIP)}\\
\hspace*\fill \hfill{China, 2007(perfect score), 2008}
\end{itemize}



%\section{SOFTWARE}

%----------------------------------------------------------------------------------------
%	INDUSTRY EXPERIENCE
%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
%	Technology SKILLS SECTION
%----------------------------------------------------------------------------------------
\section{PUBLICATIONS}
\begin{enumerate}
\item{ Xiao Wang, \textbf{Qi Lei}, Ioannis Panageas. ``Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet Log-Sobolev'',\textit{To appear at NeurIPS 2020}  }
\item{ Jason Lee, Qi Lei, Nikunj Saunshi, Jiacheng Zhuo. ``Predicting What You Already Know Helps: Provable Self-Supervised Learning'', \textit{To appear at NeurIPS 2020 Workshop: Self-Supervised Learning - Theory and Practice} }
\item{Jay Whang, Qi Lei, Alexandros G. Dimakis. ``Compressed Sensing with Invertible Generative Models and Dependent Noise'', \textit{To appear at NeurIPS 2020 Workshop on Deep Learning and Inverse Problems}  }
\item{Jiacheng Zhuo, \textbf{Qi Lei}, Alexandros G. Dimakis, Constantine 
      Caramanis.\\ ``Communication-Efficient Asynchronous Stochastic 
    Frank-Wolfe over Nuclear-norm Ball'', \textit{The 23rd International Conference on Artificial Intelligence and Statistics, 2020} }
\item{\textbf{Qi Lei}, Jason Lee, Alexandros G. Dimakis, Contantinos 
  Daskalakis. \\ ``SGD Learns One-Layer Networks in WGANs'', 
    \textit{International Conference of Machine Learning (ICML) 2020}}
  \item{ \textbf{Qi Lei}, Jiacheng Zhuo, Constantine Caramanis, Inderjit S. 
    Dhillon, Alexandros G. Dimakis. ``Primal-Dual Block Frank-Wolfe'', 
  \textit{Proc. of Neural Information Processing Systems (NeurIPS), 2019: 13866-13875} }
  \item{ \textbf{Qi Lei}, Ajil Jalal, Inderjit S. Dhillon, Alexandros G. 
      Dimakis. ``Inverting Deep Generative models, One layer at a time'', 
    \textit{Proc. of Neural Information Processing Systems (NeurIPS) 2019: 13910-13919} }

  \item{ \textbf{Qi Lei}, Jinfeng Yi, Roman Vaculin, Lingfei Wu, Inderjit S. 
      Dhillon. ``Similarity Preserving Representation Learning for Time Series 
      Analysis'', \textit{The 28th International Joint Conference on Artificial 
    Intelligence (IJCAI), 2019: 2845-2851}}
  \item{\textbf{Qi Lei}, Lingfei Wu, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S. 
    Dhillon, Michael Witbrock. ``Discrete Adversarial Attacks and Submodular 
    Optimization with Applications to Text Classification'', \textit{Systems and Machine 
  Learning (sysML), 2019} (covered by \href{https://www.nature.com/articles/d41586-019-01510-1}{Nature Story} )   }
\item{Zhewei Yao, Amir Gholami, \textbf{Qi Lei}, Kurt Keutzer, Michael W. 
  Mahoney. ``Hessian-based Analysis of Large Batch Training and Robustness to 
Adversaries'', \textit{Neural Information Processing Systems (NIPS), 2018: 4954-4964}}
  \item{Jiong Zhang, \textbf{Qi Lei}, Inderjit S. Dhillon. 
        ``Stabilizing Gradients for Deep 
       Neural Networks via Efficient SVD Parameterization'', \textit{
    International Conference of Machine Learning (ICML), 2018: 5801-5809}}
  \item{Lingfei Wu, Ian En-Hsu Yen, Jinfeng Yi, Fangli Xu, \textbf{Qi Lei}, Michael Witbrock.
    ``Random Warping Series: A Random Features Method for Time-Series Embedding'', \textit{AISTATS 2018: 793-802}}
\item{Hsiang-fu Yu, Cho-Jui Hsieh, \textbf{Qi Lei}, Inderjit S. Dhillon. 
      ``A Greedy Approach for Budgeted Maximum 
      Inner Product Search'', \textit{Neural Information Processing Systems 
      (NIPS), 2017: 5453-5462}}
    \item{\textbf{Qi Lei}, Enxu Yen, Chao-yuan Wu, Inderjit S. Dhillon, Pradeep 
        Ravikumar. ``Doubly Greedy Primal-Dual Coordinate Methods on Sparse Empirical 
  Risk Minimization'', \textit{International Conference of Machine 
    Learning (ICML), 2017: 2034-2042}}
\item{Rashish Tandon, \textbf{Qi Lei}, 
    Alexandros G. Dimakis, Nikos Karampatziakis, ``Gradient Coding: Avoiding 
    Stragglers in Distributed Learning'', \textit{International Conference of 
  Machine Learning (ICML), 2017: 3368-3376}}
  \item {\textbf{Qi Lei},
      Kai Zhong, Inderjit S. Dhillon. ``Coordinate-wise Power Method'', 
  \textit{Neural Information Processing System(NIPS), 2016: 2056-2064}}		

%\item {\textbf{Qi Lei}, Jinfeng Yi, Roman Vaculin, Inderjit Dhillon. "Similarity Preserving Representation Learning for Time Series Analysis", \textit{Submitted for publication}}
%\item {Rashish Tandon, \textbf{Qi Lei}, Alexandros G. Dimakis, Nikos  Karampatziakis. "Gradient Coding", \textit{ML Systems Workshop at NIPS, Dec. 2016}}
	\item {Arnaud Vandaele, Nicolas Gillis, \textbf{Qi Lei},
      Kai Zhong, Inderjit S. Dhillon. ``Coordinate Descent Methods for
		Symmetric Nonnegative Matrix Factorization'', \textit{IEEE Transactions on 
Signal Processing}, 64.21 (2016): 5571-5584}	
%	\item {Hsiang-Fu Yu, Cho-Jui Hsieh, \textbf{Qi Lei}, Inderjit S. Dhillon. "A Greedy Approach for Budgeted Maximum Inner Product Search", \textit{arXiv:1610.03317v1}}
	\item {Jiazhou Chen, \textbf{Qi Lei}, Yongwei Miao, Qunsheng Peng, "Vectorization of Line Drawing Image based on Junction Analysis", \textit{Science China Information Sciences}, 2014:1-14}
%	\item {Maria R. D'Orsogna, \textbf{Qi Lei}, Tom Chou, "First assembly times and equilibration in stochastic coagulation-fragmentation", \textit{The Journal of Chemical Physics}, 2015: 143.1, 014112}
	\item {Jiazhou Chen, \textbf{Qi Lei}, Fan Zhong, Qunsheng Peng, "Interactive Tensor Field Design Based on Line Singularities", \textit{Proceedings of the 13th International CAD /Graphics}, 2013}
\end{enumerate}

%----------------------------------------------------------------------------------------
%	PROFESSIONAL EXPERIENCE SECTION
%----------------------------------------------------------------------------------------
\begin{comment}
\section{SOFTWARE}
 \textit{Github: }\url{https://github.com/cecilialeiqi/}\\
 {\sl SPIRAL} \hfill May 2016 - July 2017
 \begin{itemize}
   \item Feature representation learning of any time series data
    \end{itemize}
 {\sl DDI} \hfill Jan 2017 - May 2017
 \begin{itemize}
   \item Use an inductive tensor completion based methods to predict drug-drug interactions
   \end{itemize}
   {\sl NUTF} \hfill August 2016 - February 2017
   \begin{itemize}
     \item Negative-Unlabeled Tensor Factorization for Location\ Context 
       Inference from Inaccurate Mobility Data
      \end{itemize}
 \end{itemize} 
\end{comment}

\section{TEACHING}
{\sl Department of Electrical and Computer Engineering, UT Austin} \hfill Fall 2019
\begin{itemize}
  \item Scalable Machine Learning: {\sl Teaching Assistant}
  \end{itemize}

{\sl Oden Institute for Computational Engineering and Sciences, UT Austin} \hfill Fall 2015
\begin{itemize}
  \item Mathematical Methods in Applied Engineering and Sciences: {\sl Instructor Intern}
\end{itemize}


\section{EXPERIENCE}
{\sl Institute for Advanced Study, Princeton, NJ, United States}\\
\hspace*\fill\hfill September 2019 - July 2020
\begin{itemize}
  \item Visiting Graduate Student for the ``Special Year on Optimization, Statistics, and Theoretical Machine Learning''
\end{itemize}

{\sl Simons Institute, Berkeley, CA, United States} \hfill May 2019 - August 2019
\begin{itemize}
  \item Research Fellow for the Foundations of Deep Learning Program
\end{itemize}

{\sl Facebook/Photo\&Video Search} \hfill June 2018 - September 2018
\begin{itemize}
  \item Explored offline/online evaluation gaps by estimating expected number of 
    clicks based on historical logging data.
\end{itemize}
{\sl Amazon/A9 Product Search} \hfill May 2017 - August 2017
\begin{itemize}
  \item Inline search suggestions: used deep learning methods for NLP user 
    search tasks.
\end{itemize}
{\sl Amazon Web Services (AWS Deep Learning Team)} \hfill January 2017 - April 2017
\begin{itemize}
  \item Documentations for MXNet: a deep learning framework designed for 
    both efficiency and flexibility.
  \end{itemize}
{\sl IBM Thomas J. Watson Research Center} \hfill May 2016 - October 2016
\begin{itemize}
\item  %Clients' propensity prediction of trading options
  Partnered with one of the largest American financial companies on a challenge problem of predicting its clients' propensity of trading options
\item Create World of Watson Session recommendation system:\\
  \url{https://myibm.ibm.com/events/wow/watson/}
%\item 
\end{itemize} 


\section{SERVICE}
{\sl Conference Reviewer:} MLSys (PC'21, 20), STOC (20), NeurIPS (16,17,18,19,20), ICML (18,19,20), ICLR (18,19,20,21), 
AISTATS (18,19,20,21), AAAI (20,21), ACML (19), and more

{\sl Journal Reviewer:} MOR (19), TNNLS (19), TKDE (19), ISIT (17,18), TIIS (17), 
IT (16,17), and more

\section{PATENTS}\begin{itemize}
 \item{"Method and System for General and Efficient Time Series Representation 
     Learning via Dynamic Time Warping."\\
   \textbf{Q. Lei}, J. Yi, R. Vaculin, and W. Sun}

 \item{"Real-Time Cold Start Recommendation and Rationale within a Dialog System".\\
   \textbf{Q. Lei}, J. Yi, R. Vaculin, M. Pietro}
 \end{itemize}

 \section{INVITED\\TALKS}
 \begin{itemize}
	\item{`` Few-Shot Learning via Learning the Representation, Provably.''\\
		IAS, Princeton, NJ \& Simons Institute Reunion \& UC Berkeley, 2020	}
	 \item{``Predicting What You Already Know Helps: Provable Self-Supervised Learning.''\\
		 One-World ML seminar \& UW-Madison, 2020	 } 
\item{``Deep Generative models and Inverse Problems.''\\
       Minisymposium on Machine Learning for Solving Partial Differential 
       Equations and Inverse Problems, 2019 SIAM Texas-Louisiana Section, Dallas,
 TX, USA, 2019}

 \item{``Discrete Adversarial Attacks 
 and Submodular Optimization with Applications to Text Classification.''\\ 
 Simons-Berkeley Fellows Talk, Berkeley, CA, USA \& SysML19, Stanford, CA, 
 USA, 2019}

 \item{``Recent 
     Advances in Primal-Dual Coordinate Methods for ERM.''\\
     Minisymposium on Recent Progress in Coordinate-wise Descent Methods, SIAM Conference on Computational Science and Engineering, Spokane, WA, USA, 2019}
 
 \item{``Coordinate Descent Methods for Matrix Factorization.''\\
   Minisymposium on Recent Advances in Nonnegative Matrix Factorization, SIAM 
 Annual Meeting, Boston, USA, 2016}


 \end{itemize}

\section{PROGRAMMING \\ SKILLS} 
\begin{itemize}
	\item[]  C/C++(proficient), Python(proficient), Matlab(proficient), C\#(prior experience)
  \item[]  Familiar with Deep Learning packages(Pytorch, Tensorflow, Theano, MXNet)
\end{itemize}

\end{resume}
\end{document}
