# jemdoc: menu{MENU}{index.html}
# The first line of this file is a special command that tells jemdoc which menu
# entry in the file named MENU to associate this page with.
= Qi Lei (雷琦)

~~~
{}{img_left}{Qi Lei.jpg}{Qi Lei UT Austin}{110px}{150px}{Qi Lei.jpg}
Email: qilei at princeton.edu

Website: [cecilialeiqi.github.io http:\/\/cecilialeiqi.github.io]


~~

I am an associate research scholar at ECE, Princeton University. I am fortunate to have Prof. [http://jasondlee88.github.io Jason Lee] as my research mentor. I received my Ph.D. from [https://www.oden.utexas.edu/ Oden Institute for Computational Engineering and Sciences], 
University of Texas at Austin, advised by [http://users.ece.utexas.edu/~dimakis/index.html Alexandros G. Dimakis] and [http://www.cs.utexas.edu/~inderjit/ Inderjit S. Dhillon]. 
I was also a member of [http://bigdata.ices.utexas.edu/ Center for Big Data Analytics] and [https://wncg.org/ Wireless Networking & Communications Group]. I visited [https://www.ias.edu/ IAS] for the [http://www.math.ias.edu/theoretical_machine_learning Theoretical Machine Learning program] from September 2019 to July 2020. Prior to that, I was a Research Fellow at the Simons Institute for the Theory of Computing at UC Berkeley for the program on Foundations of Deep Learning.

My research interests are *machine learning*, *deep learning* and *optimization*. Specifically, I'm interested in developing sample- and computationally efficient algorithms for some fundamental machine learning problems. 

*I will be on the 2021-22 job market.*
 
([cv_2.pdf Curriculum Vitae], [https://github.com/cecilialeiqi/ Github], [https://scholar.google.com/citations?user=kGOgaowAAAAJ&hl=en Google Scholar])


== News and Announcement
[11/2021] Invited talk in the [https://ellis.ist.ac.at/ ELLIS talk series] on [https://talks-calendar.app.ist.ac.at/events/3329 ``Provable representation learning"]

[10/2021] I'm honored to be selected as a rising star in Machine Learning at University Maryland

[10/2021] I'm honored to be selected as a rising star in EECS at MIT

[10/2021] I'm invited to give a talk on [https://simons.berkeley.edu/talks/optimal-gradient-based-algorithms-non-concave-bandit-optimization non-concave bandit optimization] at [https://simons.berkeley.edu/workshops/schedule/16590 the Sampling Algorithms and Geometries on Probability Distributions workshop] at Simons Institute

[09/2021] Four papers accepted at NeurIPS 2021:
- Baihe Huang\*, Kaixuan Huang\*, Sham M. Kakade\*, Jason D. Lee\*, *Qi Lei*\*, Runzhe Wang\*, Jiaqi Yang\* [https://arxiv.org/abs/2107.04518 ``Optimal Gradient-based Algorithms for Non-concave Bandit Optimization"]
- Baihe Huang\*, Kaixuan Huang\*, Sham M. Kakade\*, Jason D. Lee\*, *Qi Lei*\*, Runzhe Wang\*, Jiaqi Yang\* [https://arxiv.org/abs/2107.06466 ``Going Beyond Linear RL: Sample Efficient Neural Function Approximation] 
- Kurtland Chua, *Qi Lei*, Jason D. Lee, [https://arxiv.org/abs/2105.02221 ``How fine-tuning allows for effective meta-learning"]
- Jason D Lee\*, *Qi Lei*\*, Nikunj Saunshi\*, Jiacheng Zhuo\*, [https://arxiv.org/abs/2008.01064 ``Predicting What You Already Know Helps: Provable Self-Supervised Learning"]


[07/2021] New papers out:
- [https://arxiv.org/abs/2107.04518 Optimal Gradient-based Algorithms for Non-concave Bandit Optimization]
- [https://arxiv.org/abs/2107.06466 Going Beyond Linear RL: Sample Efficient Neural Function Approximation]
- [https://arxiv.org/abs/2107.02377 A Short Note on the Relationship of Information Gain and Eluder Dimension]

[05/2021] Three papers are accepted at ICML 2021:
- *Qi Lei*, Wei Hu, Jason D. Lee. [https://arxiv.org/abs/2106.12108 ``Near-Optimal Linear Regression under Distribution Shift"]
- Tianle Cai\*, Ruiqi Gao\*, Jason D Lee\*, *Qi Lei*\*.  [https://arxiv.org/abs/2102.11203 ``A Theory of Label Propagation for Subpopulation Shift"]
- Jay Whang, *Qi Lei*, Alexandros G. Dimakis. [https://arxiv.org/abs/2003.08089 ``Solving Inverse Problems with a Flow-based Noise Model"]

[05/2021] I'm invited to give a talk on [https://cms.caltech.edu/events/90169 Provable Representation Learning] at [https://eas.caltech.edu/young_investigators Caltech Young Investigators Lecture]

[05/2021] New paper out:
[https://arxiv.org/abs/2105.02221  How Fine-Tuning Allows for Effective Meta-Learning]

[03/2021] My PhD thesis [https://cecilialeiqi.github.io/LEI-DISSERTATION-2020.pdf Provably Effective Algorithms for Min-Max Optimization] won this year's [https://www.oden.utexas.edu/about/news/qi-lei-wins-Outstanding-Dissertation-Award/ Oden Institute Outstanding Dissertation Award] 

[01/2021] Our paper is accepted at AISTATS 2021:
- *Qi Lei*\*, Sai Ganesh Nagarajan\*, Ioannis Panageas\*, Xiao Wang\*. "Last iterate convergence in no-regret learning: constrained min-max optimization for convex-concave landscapes"

[01/2021] Our paper is accepted at ICLR 2021:
- Simon S. Du\*, Wei Hu\*, Sham M. Kakade\*, Jason D. Lee\*, *Qi Lei*\*. "Few-Shot Learning via Learning the Representation, Provably"

[12/2020] I'm invited to give a talk on [https://simons.berkeley.edu/talks/sgd-learns-one-layer-networks-wgans SGD learns one-layer network with WGANs] at [https://simons.berkeley.edu/workshops/hd-2020-3 Learning and Testing in High Dimensions]

[11/2020] I'm invited to give a Young Researcher Spotlight Talk at the [https://sites.google.com/view/slowdnn/ "Seeking Low-dimensionality in Deep Learning"] workshop on my recent work of [https://www.youtube.com/watch?v=SvddIPXjNDU&list=PL7P834wcUN3eSh7Nn4wzPBjEnme4Rls7n&index=15&ab_channel=SLowDNNWorkshop provable representation learning]

#[10/2020] I'm invited to give a talk on [https://www.youtube.com/watch?v=5A1iKkPv1Y0&feature=youtu.be&ab_channel=Oneworldtheoreticalmachinelearning provable self-supervised learning] at [https://www.oneworldml.org/ One-World ML seminar] 

#[10/2020] Our paper is accepted at NeurIPS 2020: 
- Xiao Wang, *Qi Lei*, Ioannis Panageas.  "Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet Log-Sobolev"

#[09/2020] I am selected as a 2020 Computing Innovation Fellow. Thank you CRA! 

#[08/2020] New paper out:
#- [https://arxiv.org/abs/2008.01064 "Predicting What You Already Know Helps: Provable Self-Supervised Learning"]

#[06/2020] Our paper is accepted at ICML 2020: 
#- *Qi Lei*, Jason D. Lee, Alexandros G. Dimakis, Constantinos Daskalakis. [https://arxiv.org/abs/1910.07030 "SGD Learns One-Layer Networks in WGANs"] 

#[03/2020] New papers out:
#- [https://arxiv.org/abs/2003.10392 "Steepest Descent Neural Architecture Optimization: Escaping Local Optimum with Signed Neural Splitting"]
#- [https://arxiv.org/abs/2003.08089 "Compressed Sensing with Invertible Generative Models and Dependent Noise"]

#[02/2020] New papers out:
#- [https://arxiv.org/abs/2002.09434 "Few-Shot Learning via Learning the Representation, Provably"]
#- [https://arxiv.org/abs/2002.06789  "CAT: Customized Adversarial Training for Improved Robustness"]
#- [https://arxiv.org/abs/2002.06768  "Last iterate convergence in no-regret learning: constrained min-max optimization for convex-concave landscapes"]

#[01/2020] Our paper is accepted to AISTATS 2020:
#- Jiacheng Zhuo, *Qi Lei*, Alexandros G. Dimakis, Constantine Caramanis. [https://arxiv.org/abs/1910.07703 "Communication-Efficient Asynchronous Stochastic Frank-Wolfe over Nuclear-norm Ball"]

#[12/2019] Attending [https://neurips.cc/ NeurIPS 2019] to present our following papers:
#- *Qi Lei*, Jiacheng Zhuo, Constantine Caramanis, Inderjit S Dhillon, Alexandros G Dimakis. [https://arxiv.org/abs/1906.02436 "Primal-Dual Block Generalized Frank-Wolfe"]
#- *Qi Lei*, Ajil Jalal, Inderjit S. Dhillon, Alexandros G. Dimakis. [https://arxiv.org/abs/1906.07437 "Inverting Deep Generative models, One layer at a time"]


#[11/2019] I am invited to give a talk on Deep Generative models and Inverse Problems at the mini-symposium "Machine Learning for Solving Partial Differential Equations and Inverse Problems" of the 2nd Annual Meeting of the [http://faculty.smu.edu/sxu/SIAMTXLA19/index.html SIAM Texas-Louisiana Section] in Dallas on Nov 2nd, 2019

#[10/2019] I am going to attend the [https://publish.illinois.edu/rising-stars/ Rising Stars 2019] at UIUC (An Academic Career Workshop for Women in EECS) from Oct 29th to Nov 1st, 2019

#[10/2019] New paper out: [https://arxiv.org/abs/1910.07703 "Communication-Efficient Asynchronous Stochastic Frank-Wolfe over Nuclear-norm Balls"]

#[10/2019] New paper out: [https://arxiv.org/abs/1910.07030 "SGD Learns One-Layer Networks in WGANs"]

#[09/2019] I am participating the [https://www.math.ias.edu/sp/Optimization_Statistics_and_Theoretical_Machine_Learning "Special Year on Optimization, Statistics, and Theoretical Machine Learning"] as a short-term visitor at the Institute of Advanced Study from September to December, 2019

#[09/2019] Two papers accepted at NeurIPS 2019
#- *Qi Lei*, Jiacheng Zhuo, Constantine Caramanis, Inderjit S Dhillon, Alexandros G Dimakis. [https://arxiv.org/abs/1906.02436 "Primal-Dual Block Frank-Wolfe"]
#- *Qi Lei*, Ajil Jalal, Inderjit S. Dhillon, Alexandros G. Dimakis. [https://arxiv.org/abs/1906.07437 "Inverting Deep Generative models, One layer at a time"]

#[05/2019] I received [https://simons.berkeley.edu/programs/fellows Simons-Berkeley fellowship] in Foundations of Deep Learning, 2019.

#[04/2019] Our sysML paper on paraphrasing attacks [https://arxiv.org/abs/1812.00151  "Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification"] was covered by [https://www.nature.com/articles/d41586-019-01510-1?utm_source=twt_nnc&utm_medium=social&utm_campaign=naturenews&sf212595612=1 Nature Story], [https://venturebeat.com/2019/04/01/text-based-ai-models-are-vulnerable-to-paraphrasing-attacks-researchers-find VectureBeat], and [https://bdtechtalks.com/2019/04/02/ai-nlp-paraphrasing-adversarial-attacks/ TechTalks] 
#[https://github.com/cecilialeiqi/adversarial_text (code], [discrete_attack.pdf slides)] 




== Selected Papers

([papers.html full publication list])

6. Baihe Huang\*, Kaixuan Huang\*, Sham M. Kakade\*, Jason D. Lee\*, *Qi Lei*\*, Runzhe Wang\*, and Jiaqi Yang\*.
[https://arxiv.org/abs/2107.04518 "Optimal Gradient-based Algorithms for Non-concave Bandit Optimization"], to appear at NeurIPS 2021

5. Jason D. Lee\*, *Qi Lei*\*, Nikunj Saunshi\*, Jiacheng Zhuo\*. [https://arxiv.org/abs/2008.01064 "Predicting What You Already Know Helps: Provable Self-Supervised Learning"], to appear at NeurIPS 2021

4. Simon S. Du\*, Wei Hu\*, Sham M. Kakade\*, Jason D. Lee\*, *Qi Lei*\*.  [https://arxiv.org/abs/2002.09434 "Few-Shot Learning via Learning the Representation, Provably"], /The International Conference on Learning Representations (ICLR) 2021/

3. *Qi Lei*, Jason D. Lee, Alexandros G. Dimakis, Constantinos Daskalakis. [https://arxiv.org/abs/1910.07030 "SGD Learns One-Layer Networks in WGANs"], /Proc. of International Conference of Machine Learning (ICML) 2020/

2. *Qi Lei*\*, Lingfei Wu\*, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S. Dhillon, Michael Witbrock. [https://arxiv.org/abs/1812.00151 "Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification"], /Systems and Machine Learning (sysML). 2019/ [https://github.com/cecilialeiqi/adversarial_text (code], [discrete_attack.pdf slides)] 
- Press coverage: [https://www.nature.com/articles/d41586-019-01510-1?utm_source=twt_nnc&utm_medium=social&utm_campaign=naturenews&sf212595612=1 <Nature Story>] [https://venturebeat.com/2019/04/01/text-based-ai-models-are-vulnerable-to-paraphrasing-attacks-researchers-find/ <Vecturebeat>] [https://bdtechtalks.com/2019/04/02/ai-nlp-paraphrasing-adversarial-attacks/ <Tech Talks>] [https://www.jiqizhixin.com/articles/2019-03-27-10?from=synced&keyword=SysML%202019 <机器之心>]


1. Rashish Tandon, *Qi Lei*, Alexandros G. Dimakis, Nikos Karampatziakis, [https://arxiv.org/abs/1612.03301 "Gradient Coding: Avoiding Stragglers in Distributed Learning"], /Proc. of International Conference of Machine Learning (ICML), 2017/ [https://github.com/rashisht1/gradient_coding (code)]




