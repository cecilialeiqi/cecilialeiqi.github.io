<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publication List</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html" class="current">Main</a></div>
<div class="menu-item"><a href="bio.html">Bio&nbsp;and&nbsp;CV</a></div>
<div class="menu-item"><a href="contact.html">Contact</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="papers.html">Publication&nbsp;List</a></div>
<div class="menu-item"><a href="https://github.com/cecilialeiqi/">Github</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publication List</h1>
</div>
<h2>Publications</h2>
<p>34. Zihan Wang, Jason Lee, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2212.03714">&lsquo;&lsquo;Reconstructing Training Data from Model Gradient, Provably"</a>, <i>AISTATS 2023</i></p>
<p>33 Shuo Yang, Yijun Dong, Rachel Ward, Inderjit Dhillon, Sujay Sanghavi, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2202.12230">&lsquo;&lsquo;Sample Efficiency of Data Augmentation Consistency Regularization"</a>, <i>AISTATS 2023</i></p>
<p>32. Kurtland Chua, <b>Qi Lei</b>, Jason Lee. <a href="https://arxiv.org/abs/2110.09507">&lsquo;&lsquo;Provable Hierarchy-Based Meta-Reinforcement Learning"</a>, <i>AISTATS 2023</i></p>
<p>31. Qian Yu, Yining Wang, Baihe Huang, <b>Qi Lei</b>, Jason Lee. &lsquo;&lsquo;Optimal Sample Complexity Bounds for Non-convex Optimization under Kurdyka-Lojasiewicz Condition", <i>AISTATS 2023</i></p>
<p>30. Chun-Yin Huang, <b>Qi Lei</b>, Xiaoxiao Li, <a href="https://arxiv.org/abs/2209.14434">Efficient Medical Image Assessment via Self-supervised Learning</a>, <i>MICCAI Workshop, DALI 2022</i>, with <b>Best Paper Honorable Mention</b></p>
<p>29. Minhao Cheng, <b>Qi Lei</b>, Pin-Yu Chen, Inderjit Dhillon, Cho-Jui Hsieh <a href="https://arxiv.org/abs/2002.06789">&lsquo;&lsquo;Cat: Customized adversarial training for improved robustness"</a>, <i>IJCAI 2022</i></p>
<p>28. Baihe Huang*, Kaixuan Huang*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*, Runzhe Wang*, Jiaqi Yang* <a href="https://arxiv.org/abs/2107.04518">&lsquo;&lsquo;Optimal Gradient-based Algorithms for Non-concave Bandit Optimization"</a>, <i>NeurIPS 2021</i></p>
<p>27. Baihe Huang*, Kaixuan Huang*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*, Runzhe Wang*, Jiaqi Yang* <a href="https://arxiv.org/abs/2107.06466">&lsquo;&lsquo;Going Beyond Linear RL: Sample Efficient Neural Function Approximation</a>, <i>NeurIPS 2021</i></p>
<p>26. Kurtland Chua, <b>Qi Lei</b>, Jason D. Lee, <a href="https://arxiv.org/abs/2105.02221">&lsquo;&lsquo;How fine-tuning allows for effective meta-learning"</a>, <i>NeurIPS 2021</i></p>
<p>25. Jason D Lee*, <b>Qi Lei</b>*, Nikunj Saunshi*, Jiacheng Zhuo*, <a href="https://arxiv.org/abs/2008.01064">&lsquo;&lsquo;Predicting What You Already Know Helps: Provable Self-Supervised Learning"</a>, <i>NeurIPS 2021</i></p>
<p>24. Tianle Cai*, Ruiqi Gao*, Jason D Lee*, <b>Qi Lei</b>*. <a href="https://arxiv.org/abs/2102.11203">&lsquo;&lsquo;A Theory of Label Propagation for Subpopulation Shift"</a>, <i>ICML 2021</i></p>
<p>23. <b>Qi Lei</b>, Wei Hu, Jason D. Lee. <a href="https://arxiv.org/abs/2106.12108">&lsquo;&lsquo;Near-Optimal Linear Regression under Distribution Shift"</a>, <i>ICML 2021</i></p>
<p>22. Jay Whang, <b>Qi Lei</b>, Alexandros G. Dimakis. <a href="https://arxiv.org/abs/2003.08089">&ldquo;Solving Inverse Problems with a Flow-based Noise Model&rdquo;</a>, <i>ICML 2021</i></p>
<p>21. <b>Qi Lei</b>*, Sai Ganesh Nagarajan*, Ioannis Panageas*, Xiao Wang*. <a href="https://arxiv.org/abs/2002.06768">&ldquo;Last iterate convergence in no-regret learning: constrained min-max optimization for convex-concave landscapes&rdquo;</a>, <i>AISTATS 2021</i></p>
<p>20. Simon S. Du*, Wei Hu*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*.  <a href="https://arxiv.org/abs/2002.09434">&ldquo;Few-Shot Learning via Learning the Representation, Provably&rdquo;</a>, <i>ICLR 2021</i></p>
<p>19. Xiao Wang, <b>Qi Lei</b>, Ioannis Panageas. &ldquo;Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet Log-Sobolev&rdquo;, <i>Proc. of Neural Information Processing Systems (NeurIPS), 2020</i></p>
<p>18. <b>Qi Lei</b>, Jason D. Lee, Alexandros G. Dimakis, Constantinos Daskalakis. <a href="https://arxiv.org/abs/1910.07030">&ldquo;SGD Learns One-Layer Networks in WGANs&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML) 2020</i></p>
<p>17. Jiacheng Zhuo, <b>Qi Lei</b>, Alexandros G. Dimakis, Constantine Caramanis. <a href="https://arxiv.org/abs/1910.07703">&ldquo;Communication-Efficient Asynchronous Stochastic Frank-Wolfe over Nuclear-norm Balls&rdquo;</a>, <i>AISTATS 2020</i></p>
<p>16. <b>Qi Lei</b>, Jiacheng Zhuo, Constantine Caramanis, Inderjit S Dhillon, Alexandros G Dimakis. <a href="https://arxiv.org/abs/1906.02436">&ldquo;Primal-Dual Block Frank-Wolfe&rdquo;</a>, <i>Proc. of Neural Information Processing Systems (NeurIPS) 2019</i> (<a href="PDBFW.pdf">slides</a>, <a href="PDBFW_poster.pdf">poster</a>, <a href="https://github.com/CarlsonZhuo/primal_dual_frank_wolfe">code</a>)</p>
<p>15. <b>Qi Lei</b>, Ajil Jalal, Inderjit S. Dhillon, Alexandros G. Dimakis. <a href="https://arxiv.org/abs/1906.07437">&ldquo;Inverting Deep Generative models, One layer at a time&rdquo;</a>, <i>Proc. of Neural Information Processing Systems (NeurIPS) 2019</i> (<a href="invert_GAN_poster.pdf">poster</a>, <a href="https://github.com/cecilialeiqi/InvertGAN_LP">code</a>)</p>
<p>14. <b>Qi Lei</b>, Jinfeng Yi, Roman Vaculin, Lingfei Wu, Inderjit Dhillon. <a href="https://arxiv.org/abs/1702.03584">&ldquo;Similarity Preserving
Representation Learning for Time Series Analysis&rdquo;</a>, <i>The 28th International Joint Conference on Artificial Intelligence (IJCAI), 2019</i>. <a href="https://github.com/cecilialeiqi/SPIRAL">(code)</a></p>
<p>13. <b>Qi Lei</b>, Lingfei Wu, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S. Dhillon, Michael Witbrock. <a href="https://arxiv.org/abs/1812.00151">&ldquo;Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification&rdquo;</a>, <i>Systems and Machine Learning (sysML). 2019</i> <a href="https://github.com/cecilialeiqi/adversarial_text">(code</a>, <a href="discrete_attack.pdf">slides)</a> </p>
<ul>
<li><p>Press coverage: <a href="https://www.nature.com/articles/d41586-019-01510-1?utm_source=twt_nnc&amp;utm_medium=social&amp;utm_campaign=naturenews&amp;sf212595612=1">&lt;Nature Story&gt;</a> <a href="https://venturebeat.com/2019/04/01/text-based-ai-models-are-vulnerable-to-paraphrasing-attacks-researchers-find/">&lt;Vecturebeat&gt;</a> <a href="https://bdtechtalks.com/2019/04/02/ai-nlp-paraphrasing-adversarial-attacks/">&lt;Tech Talks&gt;</a> <a href="https://www.jiqizhixin.com/articles/2019-03-27-10?from=synced&amp;keyword=SysML%202019">&lt;机器之心&gt;</a></p>
</li>
</ul>
<p>12. Jinfeng Yi, <b>Qi Lei</b>,  Wesley Gifford, Ji Liu. <a href="https://arxiv.org/pdf/1702.06362.pdf">&ldquo;Negative-Unlabeled Tensor Factorization for Location Category Inference from Inaccurate Mobility Data&rdquo;</a>, <i>SIAM International Conference on Data Mining (SDM), 2019</i> <a href="https://github.com/cecilialeiqi/NUTF">(code)</a></p>
<p>11. Zhewei Yao, Amir Gholami, <b>Qi Lei</b>, Kurt Keutzer, Michael W. Mahoney. <a href="https://arxiv.org/abs/1802.08241">&ldquo;Hessian-based Analysis of Large Batch Training and Robustness to Adversaries&rdquo;</a>, <i>Neural Information Processing Systems (NIPS), 2018</i></p>
<p>10. Jiong Zhang, <b>Qi Lei</b>, Inderjit Dhillon, <a href="http://proceedings.mlr.press/v80/zhang18g.html">&ldquo;Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization&rdquo;</a>, <i>International Conference of Machine Learning (ICML), July. 2018</i></p>
<p>9. Lingfei Wu, Ian En-Hsu Yen, Jinfeng Yi, Fangli Xu, <b>Qi Lei</b> and Michael Witbrock, <a href="http://proceedings.mlr.press/v84/wu18b.html">&ldquo;Random Warping Series: A Random Features Method for Time-Series Embedding&rdquo;</a>, <i>Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics (AISTATS), 2018</i></p>
<p>8. Hsiang-fu Yu, Cho-Jui Hsieh, <b>Qi Lei</b>, Inderjit Dhillon, <a href="https://arxiv.org/abs/1610.03317">&ldquo;A Greedy Approach for Budgeted Maximum Inner Product Search&rdquo;</a>, <i>Proc. of Neural Information Processing Systems (NIPS), 2017</i> </p>
<p>7. <b>Qi Lei</b>, Enxu Yan, Chao-yuan Wu, Pradeep Ravikumar, Inderjit Dhillon, <a href="DGPDC.pdf">&ldquo;Doubly Greedy Primal-Dual Coordinate Methods for Sparse Empirical Risk Minimization&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML), 2017</i> <a href="https://github.com/a061105/Primal-Dual-ActiveCD">(code)</a></p>
<p>6. Rashish Tandon, <b>Qi Lei</b>, Alexandros G. Dimakis, Nikos Karampatziakis, <a href="https://arxiv.org/abs/1612.03301">&ldquo;Gradient Coding: Avoiding Stragglers in Distributed Learning&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML), 2017</i> <a href="https://github.com/rashisht1/gradient_coding">(code)</a></p>
<p>5. <b>Qi Lei</b>, Kai Zhong, Inderjit. Dhillon, <a href="http://users.ices.utexas.edu/~leiqi/CPM.pdf">&ldquo;Coordinate-wise Power Method&rdquo;</a>, <i>Proc. of Neural Information Processing
Systems (NIPS), Dec. 2016</i> (<a href="https://github.com/cecilialeiqi/CPM">code</a>,<a href="cpm_poster.pdf">poster</a>)</p>
<p>4. Arnaud Vandaele, Nicolas Gillis, <b>Qi Lei</b>, Kai Zhong, Inderjit Dhillon, <a href="http://users.ices.utexas.edu/~leiqi/symNMF.pdf">&ldquo;Efficient and Non-Convex Coordinate Descent Methods for Symmetric Nonnegative Matrix Factorization&rdquo;</a>, <i>IEEE Transactions on Signal Processing 64.21 (2016): 5571-5584</i> <a href="https://www.dropbox.com/s/rh24r7cf1qxiv6k/symNMF%20-%20code%20Arnaud.zip?dl=0">(code)</a></p>
<p>3. Maria R. D'Orsogna, <b>Qi Lei</b>, Tom Chou, <a href="https://www.csun.edu/~dorsogna/mwebsite/papers/coagfrag_TC15.pdf">&ldquo;First assembly times and equilibration in stochastic coagulation-fragmentation&rdquo;</a>, <i>The Journal of Chemical Physics, 2015: 143.1, 014112</i></p>
<p>2. Jiazhou Chen, <b>Qi Lei</b>, Yongwei Miao, Qunsheng Peng, <a href="vectorization.pdf">&ldquo;Vectorization of Line Drawing Image based on Junction Analysis&rdquo;</a>, <i>Science China Information Sciences, 2014:1-14</i> <a href="vectorization/vector.zip">(code)</a></p>
<p>1. Jiazhou Chen, <b>Qi Lei</b>, Fan Zhong, Qunsheng Peng, <a href="imagePro.pdf">&ldquo;Interactive Tensor Field Design Based on Line Singularities&rdquo;</a>, <i>Proceedings of the 13th International CAD/Graphics, 2013</i> <a href="imagePro/imagePro.zip">(code)</a></p>
<h2>Dissertation</h2>
<p><a href="https://cecilialeiqi.github.io/LEI-DISSERTATION-2020.pdf">&ldquo;Provably Effective Algorithms for Min-Max Optimization&rdquo;</a> May, 2020
with <a href="https://www.oden.utexas.edu/about/news/qi-lei-wins-Outstanding-Dissertation-Award/">Oden Institute Outstanding Dissertation Award</a></p>
<h2>Patents</h2>
<p>&ldquo;Method and System for General and Efficient Time Series Representation Learning via Dynamic Time Warping&rdquo; <br />
with J. Yi, R. Vaculin, W. Sun</p>
<p>&ldquo;Real-Time Cold Start Recommendation and Rationale within a Dialog System&rdquo; <br />
with J. Yi, R. Vaculin, M. Pietro</p>
<div id="footer">
<div id="footer-text">
Page generated 2023-04-23 14:17:24 Eastern Daylight Time, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
