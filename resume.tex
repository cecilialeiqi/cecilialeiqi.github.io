%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Medium Length Graduate Curriculum Vitae
% LaTeX Template
% Version 1.1 (9/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Rensselaer Polytechnic Institute (http://www.rpi.edu/dept/arc/training/latex/resumes/)
%
% Important note:
% This template requires the res.cls file to be in the same directory as the
% .tex file. The res.cls file provides the resume style used for structuring the
% document.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[margin, 10pt]{res} % Use the res.cls style, the font size can be changed to 11pt or 12pt here
\usepackage{hyperref}

\usepackage{helvet} % Default font is the helvetica postscript font
%\usepackage{newcent} % To change the default font to the new century schoolbook postscript font uncomment this line and comment the one above
\usepackage{enumitem}
\usepackage{url}
\usepackage{comment}
\setlength{\textwidth}{5.1in} % Text width of the document

\begin{document}

%----------------------------------------------------------------------------------------
%	NAME AND ADDRESS SECTION
%----------------------------------------------------------------------------------------

\moveleft.5\hoffset\centerline{\large\bf Lei, Qi} % Your name at the top
 
\moveleft\hoffset\vbox{\hrule width\resumewidth height 1pt}\smallskip % Horizontal line after name; adjust line thickness by changing the '1pt'
 
\moveleft.5\hoffset\centerline{Website: \url{https://cecilialeiqi.github.io/}}
\moveleft.5\hoffset\centerline{Google Scholar: \url{https://scholar.google.com/citations?user=kGOgaowAAAAJ&hl=en}}
\moveleft.5\hoffset\centerline{Email: \url{qilei@princeton.edu}}
%----------------------------------------------------------------------------------------

\begin{resume}

%----------------------------------------------------------------------------------------
%	OBJECTIVE SECTION
%----------------------------------------------------------------------------------------
 
%\section{RESEARCH\\ INTERESTS}  
%\textbf{Machine Learning:} Provable, efficient and robust algorithms for 
%fundamental machine learning problems, distributed and parallel learning, 
%min-max optimizations with applications to generative adversarial networks and adversarial training

%\textbf{Large-Scale Optimization:} Novel algorithms that exploit 
%the underlying problem structure and are scalable to massive data sets

%\textbf{Deep Learning:} 


%My research interests mainly focus on machine learning, numerical optimization and their applications, such as matrix completion and recommendation system.
%To obtain a career that will allow myself to take full advantage of my passion and experience in software engineering and computer science. 

%----------------------------------------------------------------------------------------
%	EDUCATION SECTION
%----------------------------------------------------------------------------------------


%\section{Research\\ Interests}
%My research aims to bridge the theoretical and empirical boundary of modern machine learning algorithms, with a focus on large-scale optimization and representation/transfer learning. 
\begin{comment} 
\textbf{Large-scale optimization:}
\begin{itemize}
	\item Efficient and scalable optimization algorithm design: exploiting problem's underlying structure
	\item Two-player games: customized adversarial robustness and generative adversarial network training 
	\item Distributed systems: gradient coding and asynchronous distributed learning 
\end{itemize}
\textbf{Representation Learning and Transfer Learning}
\begin{itemize}
\item Statistical learning theory of representation with supervised pretraining, fine-tuning and self-supervised learning
%\item Domain adaptation with covariate shift and through label propagation
\item Application to meta-reinforcement learning 
\end{itemize}
Applications:
\begin{itemize}
	\item Inverse problems with generative models
\end{itemize}
\end{comment} 

\section{Professional\\Experience}
{\sl New York University, NY, United States} \hfill September 2022 - 
\begin{itemize}
	\item {\sl Assistant Professor in Mathematics and Data Science},  Courant Institute of Mathematical Sciences and the Center for Data Science 
\end{itemize} 

{\sl Princeton University, NJ, United States} \hfill July 2020 - August 2022
\begin{itemize}
	\item {\sl Associate Research Scholar and Postdoc Research Associate (\href{https://cifellows2020.org/}{CIFellow})}, Electrical and Computer Engineering Department  
	\item Mentor: \href{https://jasondlee88.github.io/}{Jason D. Lee}
\end{itemize}

{\sl Institute for Advanced Study, Princeton, NJ, United States}\\
\hspace*\fill\hfill September 2019 - July 2020
\begin{itemize}
	\item Visiting Graduate Student for the \href{https://www.ias.edu/math/sp/Optimization_Statistics_and_Theoretical_Machine_Learning}{``Special Year on Optimization, Statistics, and Theoretical Machine Learning''}
\end{itemize}

{\sl Simons Institute, Berkeley, CA, United States} \hfill May 2019 - August 2019
\begin{itemize}
	\item Research Fellow for the \href{https://simons.berkeley.edu/programs/dl2019}{Foundations of Deep Learning Program}
\end{itemize}

{\sl Amazon/A9 Product Search} \hfill May 2017 - August 2017
\begin{itemize}
	\item Inline search suggestions
\end{itemize}

{\sl Amazon Web Services (AWS Deep Learning Team)} \hfill January 2017 - April 2017
\begin{itemize}
	\item Deep Learning Tutorial
\end{itemize}

\section{Education}
{\sl University of Texas at Austin, TX, United States} \hfill August 2014 - May 2020
\begin{itemize}
	\item {\sl Ph.D., \href{https://oden.utexas.edu/}{Oden Institute for Computational Sciences and Engineering}} 
	\item Advisors: \href{https://users.ece.utexas.edu/~dimakis/}{Alexandros 
		G. Dimakis}  and \href{https://www.cs.utexas.edu/~inderjit/}{Inderjit S. Dhillon}
\end{itemize} 








%\section{SOFTWARE}

%----------------------------------------------------------------------------------------
%	INDUSTRY EXPERIENCE
%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
%	Technology SKILLS SECTION
%----------------------------------------------------------------------------------------

%\newpage
\section{Selected \\ Publications\\
	\vspace{4pt}
{\footnotesize ($*$ indicates\\ $\alpha$-$\beta$ order) }}
\begin{enumerate}
\item{Jianwei Li, \textbf{Qi Lei}, Wei Cheng, Dongkuan Xu. ``Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models", \textit{To appear at EMNLP conference, 2023}}

%\item{Jianwei Li, Weizhi Gao, \textbf{Qi Lei}, Dongkuan Xu. ``Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection", \textit{To appear at EMNLP findings, 2023}}
	
%\item{Tianci Liu, Tong Yang, Quan Zhang, \textbf{Qi Lei}. ``Optimization for Amortized Inverse Problems", \textit{International Conference of Machine Learning (ICML), 2023}}
	
\item{Zihan Wang, Jason Lee, \textbf{Qi Lei}. ``Reconstructing Training Data from Model Gradient, Provably", \textit{AISTATS 2023: 6595-6612}}
	

	

	

	
		\item {Jason D. Lee*, \textbf{Qi Lei}*, Nikunj Saunshi*, Jiacheng Zhuo*, ``Predicting What You Already Know Helps: Provable Self-Supervised Learning‚Äù, \textit{NeurIPS 2021: 309-323}}





	

	\item{Simon S. Du*, Wei Hu*, Sham M. Kakade*, Jason D. Lee*, \textbf{Qi Lei}*. ``Few-Shot Learning via Learning the Representation, Provably'', \textit{ ICLR), 2021} }
	


  \item{ \textbf{Qi Lei}, Ajil Jalal, Inderjit S. Dhillon, Alexandros G. 
      Dimakis. ``Inverting Deep Generative models, One layer at a time'', 
    \textit{NeurIPS 2019: 13910-13919} }

  \item{\textbf{Qi Lei}, Lingfei Wu, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S. 
    Dhillon, Michael Witbrock. ``Discrete Adversarial Attacks and Submodular 
    Optimization with Applications to Text Classification'', \textit{MLSys 2019} (\textbf{covered by \href{https://www.nature.com/articles/d41586-019-01510-1}{Nature News} )  } }

\end{enumerate}


\end{resume}
\end{document}
