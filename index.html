<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Qi Lei (雷琦)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html" class="current">Main</a></div>
<div class="menu-item"><a href="bio.html">Bio&nbsp;and&nbsp;CV</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="papers.html">Publication&nbsp;List</a></div>
<div class="menu-item"><a href="https://github.com/cecilialeiqi/">Github</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Qi Lei (雷琦)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="Qi Lei.jpg"><img src="Qi Lei.jpg" alt="Qi Lei UT Austin" width="110px" height="150px" /></a>&nbsp;</td>
<td align="left"><p>Email: leiqi at ices.utexas.edu</p>
<p>Website: <a href="cecilialeiqi.github.io">http://cecilialeiqi.github.io</a></p>
</td></tr></table>
<p>As of May 2020, I received my Ph.D. from <a href="https://www.oden.utexas.edu/">Oden Institute for Computational Engineering and Sciences</a>, 
University of Texas at Austin. I was fortunate to be advised by <a href="http://users.ece.utexas.edu/~dimakis/index.html">Alexandros G. Dimakis</a> and <a href="http://www.cs.utexas.edu/~inderjit/">Inderjit S. Dhillon</a>. 
I was also a member of <a href="http://bigdata.ices.utexas.edu/">Center for Big Data Analytics</a> and <a href="https://wncg.org/">Wireless Networking &amp; Communications Group</a>. I'm currently visiting <a href="https://www.ias.edu/">IAS</a> for the <a href="http://www.math.ias.edu/theoretical_machine_learning">Theoretical Machine Learning program</a> from September 2019 to July 2020. Prior to that, I was a Research Fellow at the Simons Institute for the Theory of Computing at UC Berkeley for the program on Foundations of Deep Learning.</p>
<p>My research interests are <b>machine learning</b>, <b>deep learning</b> and <b>optimization</b>. Specifically, I'm interested in developing provably efficient and robust algorithms for some fundamental machine learning problems. </p>
<p>(<a href="cv_2.pdf">Curriculum Vitae</a>, <a href="https://github.com/cecilialeiqi/">Github</a>, <a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&amp;hl=en">Google Scholar</a>)</p>
<h2>News and Announcement</h2>
<p><a href="06/2020">06/2020</a> Our paper is accepted at ICML 2020: </p>
<ul>
<li><p><b>Qi Lei</b>, Jason D. Lee, Alexandros G. Dimakis, Constantinos Daskalakis. <a href="https://arxiv.org/abs/1910.07030">&ldquo;SGD Learns One-Layer Networks in WGANs&rdquo;</a> </p>
</li>
</ul>
<p><a href="03/2020">03/2020</a> New papers out:</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2003.10392">&ldquo;Steepest Descent Neural Architecture Optimization: Escaping Local Optimum with Signed Neural Splitting&rdquo;</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2003.08089">&ldquo;Compressed Sensing with Invertible Generative Models and Dependent Noise&rdquo;</a></p>
</li>
</ul>
<p><a href="02/2020">02/2020</a> New papers out:</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2002.09434">&ldquo;Few-Shot Learning via Learning the Representation, Provably&rdquo;</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2002.06789">&ldquo;CAT: Customized Adversarial Training for Improved Robustness&rdquo;</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2002.06768">&ldquo;Last iterate convergence in no-regret learning: constrained min-max optimization for convex-concave landscapes&rdquo;</a></p>
</li>
</ul>
<p><a href="01/2020">01/2020</a> Our paper is accepted to AISTATS 2020:</p>
<ul>
<li><p>Jiacheng Zhuo, <b>Qi Lei</b>, Alexandros G. Dimakis, Constantine Caramanis. <a href="https://arxiv.org/abs/1910.07703">&ldquo;Communication-Efficient Asynchronous Stochastic Frank-Wolfe over Nuclear-norm Ball&rdquo;</a></p>
</li>
</ul>
<p><a href="12/2019">12/2019</a> Attending <a href="https://neurips.cc/">NeurIPS 2019</a> to present our following papers:</p>
<ul>
<li><p><b>Qi Lei</b>, Jiacheng Zhuo, Constantine Caramanis, Inderjit S Dhillon, Alexandros G Dimakis. <a href="https://arxiv.org/abs/1906.02436">&ldquo;Primal-Dual Block Generalized Frank-Wolfe&rdquo;</a></p>
</li>
<li><p><b>Qi Lei</b>, Ajil Jalal, Inderjit S. Dhillon, Alexandros G. Dimakis. <a href="https://arxiv.org/abs/1906.07437">&ldquo;Inverting Deep Generative models, One layer at a time&rdquo;</a></p>
</li>
</ul>
<p><a href="11/2019">11/2019</a> I am invited to give a talk on Deep Generative models and Inverse Problems at the mini-symposium &ldquo;Machine Learning for Solving Partial Differential Equations and Inverse Problems&rdquo; of the 2nd Annual Meeting of the <a href="http://faculty.smu.edu/sxu/SIAMTXLA19/index.html">SIAM Texas-Louisiana Section</a> in Dallas on Nov 2nd, 2019</p>
<p><a href="10/2019">10/2019</a> I am going to attend the <a href="https://publish.illinois.edu/rising-stars/">Rising Stars 2019</a> at UIUC (An Academic Career Workshop for Women in EECS) from Oct 29th to Nov 1st, 2019</p>
<p><a href="10/2019">10/2019</a> New paper out: <a href="https://arxiv.org/abs/1910.07703">&ldquo;Communication-Efficient Asynchronous Stochastic Frank-Wolfe over Nuclear-norm Balls&rdquo;</a></p>
<p><a href="10/2019">10/2019</a> New paper out: <a href="https://arxiv.org/abs/1910.07030">&ldquo;SGD Learns One-Layer Networks in WGANs&rdquo;</a></p>
<p><a href="09/2019">09/2019</a> I am participating the <a href="https://www.math.ias.edu/sp/Optimization_Statistics_and_Theoretical_Machine_Learning">&ldquo;Special Year on Optimization, Statistics, and Theoretical Machine Learning&rdquo;</a> as a short-term visitor at the Institute of Advanced Study from September to December, 2019</p>
<p><a href="09/2019">09/2019</a> Two papers accepted at NeurIPS 2019</p>
<ul>
<li><p><b>Qi Lei</b>, Jiacheng Zhuo, Constantine Caramanis, Inderjit S Dhillon, Alexandros G Dimakis. <a href="https://arxiv.org/abs/1906.02436">&ldquo;Primal-Dual Block Frank-Wolfe&rdquo;</a></p>
</li>
<li><p><b>Qi Lei</b>, Ajil Jalal, Inderjit S. Dhillon, Alexandros G. Dimakis. <a href="https://arxiv.org/abs/1906.07437">&ldquo;Inverting Deep Generative models, One layer at a time&rdquo;</a></p>
</li>
</ul>
<p><a href="05/2019">05/2019</a> I received <a href="https://simons.berkeley.edu/programs/fellows">Simons-Berkeley fellowship</a> in Foundations of Deep Learning, 2019.</p>
<p><a href="04/2019">04/2019</a> Our sysML paper on paraphrasing attacks <a href="https://arxiv.org/abs/1812.00151">&ldquo;Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification&rdquo;</a> was covered by <a href="https://www.nature.com/articles/d41586-019-01510-1?utm_source=twt_nnc&amp;utm_medium=social&amp;utm_campaign=naturenews&amp;sf212595612=1">Nature Story</a>, <a href="https://venturebeat.com/2019/04/01/text-based-ai-models-are-vulnerable-to-paraphrasing-attacks-researchers-find">VectureBeat</a>, and <a href="https://bdtechtalks.com/2019/04/02/ai-nlp-paraphrasing-adversarial-attacks/">TechTalks</a> 
<a href="https://github.com/cecilialeiqi/adversarial_text">(code</a>, <a href="discrete_attack.pdf">slides)</a> </p>
<h2>Selected Papers</h2>
<p>(<a href="papers.html">full publication list</a>)</p>
<p>7. Simon S. Du*, Wei Hu*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*.  <a href="https://arxiv.org/abs/2002.09434">&ldquo;Few-Shot Learning via Learning the Representation, Provably&rdquo;</a>, <i>arxiv preprint</i></p>
<p>6. <b>Qi Lei</b>, Jason D. Lee, Alexandros G. Dimakis, Constantinos Daskalakis. <a href="https://arxiv.org/abs/1910.07030">&ldquo;SGD Learns One-Layer Networks in WGANs&rdquo;</a>, <i>arxiv preprint</i></p>
<p>5. <b>Qi Lei</b>, Jiacheng Zhuo, Constantine Caramanis, Inderjit S Dhillon, Alexandros G Dimakis. <a href="https://arxiv.org/abs/1906.02436">&ldquo;Primal-Dual Block Frank-Wolfe&rdquo;</a>, <i> Proc. of Neural Information Processing Systems (NeurIPS) 2019</i> (<a href="PDBFW.pdf">slides</a>, <a href="https://github.com/CarlsonZhuo/primal_dual_frank_wolfe">code</a>)</p>
<p>4. <b>Qi Lei</b>, Ajil Jalal, Inderjit S. Dhillon, Alexandros G. Dimakis. <a href="https://arxiv.org/abs/1906.07437">&ldquo;Inverting Deep Generative models, One layer at a time&rdquo;</a>, <i> Proc. of Neural Information Processing Systems (NeurIPS) 2019</i> (<a href="invert_GAN_poster.pdf">poster</a>, <a href="https://github.com/cecilialeiqi/InvertGAN_LP">code</a>)</p>
<p>3. <b>Qi Lei</b>*, Lingfei Wu*, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S. Dhillon, Michael Witbrock. <a href="https://arxiv.org/abs/1812.00151">&ldquo;Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification&rdquo;</a>, <i>Systems and Machine Learning (sysML). 2019</i> <a href="https://github.com/cecilialeiqi/adversarial_text">(code</a>, <a href="discrete_attack.pdf">slides)</a> </p>
<ul>
<li><p>Press coverage: <a href="https://www.nature.com/articles/d41586-019-01510-1?utm_source=twt_nnc&amp;utm_medium=social&amp;utm_campaign=naturenews&amp;sf212595612=1">&lt;Nature Story&gt;</a> <a href="https://venturebeat.com/2019/04/01/text-based-ai-models-are-vulnerable-to-paraphrasing-attacks-researchers-find/">&lt;Vecturebeat&gt;</a> <a href="https://bdtechtalks.com/2019/04/02/ai-nlp-paraphrasing-adversarial-attacks/">&lt;Tech Talks&gt;</a> <a href="https://www.jiqizhixin.com/articles/2019-03-27-10?from=synced&amp;keyword=SysML%202019">&lt;机器之心&gt;</a></p>
</li>
</ul>
<p>2. <b>Qi Lei</b>, Enxu Yan, Chao-yuan Wu, Pradeep Ravikumar, Inderjit Dhillon, <a href="DGPDC.pdf">&ldquo;Doubly Greedy Primal-Dual Coordinate Methods for Sparse Empirical Risk Minimization&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML), 2017</i> <a href="https://github.com/a061105/Primal-Dual-ActiveCD">(code)</a></p>
<p>1. Rashish Tandon, <b>Qi Lei</b>, Alexandros G. Dimakis, Nikos Karampatziakis, <a href="https://arxiv.org/abs/1612.03301">&ldquo;Gradient Coding: Avoiding Stragglers in Distributed Learning&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML), 2017</i> <a href="https://github.com/rashisht1/gradient_coding">(code)</a></p>
<div id="footer">
<div id="footer-text">
Page generated 2020-06-08 15:02:23 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
