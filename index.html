<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Qi Lei (雷琦)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html" class="current">Main</a></div>
<div class="menu-item"><a href="bio.html">Bio&nbsp;and&nbsp;CV</a></div>
<div class="menu-item"><a href="contact.html">Contact</a></div>
<div class="menu-item"><a href="teaching.html">DS-GA3001</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="papers.html">Publication&nbsp;List</a></div>
<div class="menu-item"><a href="https://github.com/cecilialeiqi/">Github</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Qi Lei (雷琦)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="Qi Lei.jpg"><img src="Qi Lei.jpg" alt="Qi Lei NYU" width="173px" height="225px" /></a>&nbsp;</td>
<td align="left"><p>Assistant Professor of Mathematics and Data Science, and, by courtesy,<br />
Assistant Professor of Computer Science,<br />
Member of <a href="https://wp.nyu.edu/cilvr/">CILVR lab</a>,<br />
Member of <a href="https://mad.cds.nyu.edu/">Math and Data</a>,<br />
<a href="https://www.courant.nyu.edu/">Courant Institute of Mathematical Sciences</a> and <a href="https://cds.nyu.edu/">Center for Data Science</a>,<br />
<a href="https://www.nyu.edu/">New York University</a></p>
<p>Email: ql518 at nyu.edu</p>
</td></tr></table>
<h2>Research Overview</h2>
<p>My research interests are <b>machine learning</b>, <b>deep learning</b>, and <b>optimization</b>. Specifically, I am interested in developing sample- and computationally efficient algorithms for some fundamental machine learning problems. </p>
<p>(<a href="cv_2.pdf">Curriculum Vitae</a>, <a href="https://github.com/cecilialeiqi/">Github</a>, <a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&amp;hl=en">Google Scholar</a>)</p>
<h2>Advertisement</h2>
<p>I am actively looking for self-motivated and proactive students to work with. You are welcome to shoot me an email with your CV and short research plans/interests. (You may refer to this <a href="https://docs.google.com/document/d/1D1qBdVsTXb4VF18uAO2OfMRq9NNGTtkb3Lx2UYE3HS4/edit?usp=sharing">link</a> to see whether our research interests match.) </p>
<p>For Ph.D. applicants, please apply to <a href="https://math.nyu.edu/dynamic/graduate/phd-mathematics/admission-policies/">Courant Mathematics</a> or <a href="https://cds.nyu.edu/phd-program/">Center for Data Science</a> whichever you see fit and mention my name in your application. I do not plan to admit students from Courant CS for now.</p>
<p>For prospective students or interns who want to work with me in short term, please fill out <a href="https://forms.gle/bfV5598RaBkrEvMi7">this form</a> so that we could find a suitable project for you. </p>
<p>For prospective post-doc applicants, I encourage you to apply for the positions of <a href="https://cds.nyu.edu/fellowsjobs/">CDS Faculty Fellows</a>, <a href="https://math.nyu.edu/dynamic/research/postdoctoral-and-visitor-programs/">Courant Instructors</a>, and <a href="https://www.simonsfoundation.org/grant/flatiron-research-fellow-opportunities/">Flatiron Research Fellows</a>. </p>
<h2>News and Announcement</h2>
<p><a href="01/2024">01/2024</a> Presented our recent paper <a href="https://openreview.net/pdf?id=MlgnGWdqWl">Exploring Minimally Sufficient Representation in
Active Learning through Label-Irrelevant Patch
Augmentation</a><a href="https://cecilialeiqi.github.io/CPAL_active_learning">(slides)</a> at <a href="https://cpal.cc/">CPAL2024</a></p>
<p><a href="10/2023">10/2023</a> I am a co-PI on the <a href="https://rome.cims.nyu.edu/">ROME: Reduced Modeling with Extreme Data project</a>, a Department of Energy project developing Science Foundations for Energy Earthshots. More information is in the <a href="https://www.energy.gov/articles/doe-announces-264-million-basic-research-support-energy-earthshotstm">DOE press release</a>.</p>
<p><a href="10/2023">10/2023</a> Two papers (1 main + 1 findings) accepted at EMNLP 2023:</p>
<ul>
<li><p>Jianwei Li, <b>Qi Lei</b>, Wei Cheng, Dongkuan Xu. <a href="https://arxiv.org/abs/2310.13191">&lsquo;&lsquo;Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models"</a></p>
</li>
<li><p>Jianwei Li, Weizhi Gao, <b>Qi Lei</b>, Dongkuan Xu. <a href="https://arxiv.org/abs/2310.13183">&lsquo;&lsquo;Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection"</a> </p>
</li>
</ul>
<p><a href="09/2023">09/2023</a> Two papers accepted at Neurips 2023:</p>
<ul>
<li><p>Yijun Dong, Kevin Miller, <b>Qi Lei</b>, Rachel Ward. <a href="https://arxiv.org/pdf/2307.11030">&lsquo;&lsquo;Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering"</a></p>
</li>
<li><p>Qian Yu, Yining Wang, Baihe Huang, <b>Qi Lei</b>, Jason D. Lee. <a href="https://arxiv.org/pdf/2306.12383">&lsquo;&lsquo;Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms"</a></p>
</li>
</ul>
<p><a href="08/2023">08/2023</a> Won the <a href="https://www.nyu.edu/content/dam/nyu/provost/documents/Research/2017_Whitehead_Fellowship.pdf">Whitehead Fellowship for Junior Faculty in Biomedical and Biological Sciences</a></p>
<p><a href="06/2023">06/2023</a> New papers out:</p>
<ul>
<li><p><a href="https://arxiv.org/pdf/2307.11030">Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/2306.12383">Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms</a></p>
</li>
</ul>
<p><a href="04/2023">04/2023</a> Paper accepted at ICML 2023: </p>
<ul>
<li><p>Tianci Liu, Tong Yang, Quan Zhang, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2210.13983">&lsquo;&lsquo;Optimization for Amortized Inverse Problems"</a></p>
</li>
</ul>
<p><a href="04/2023">04/2023</a> Won the NYU Research Catalyst Prize jointly with <a href="https://www.stern.nyu.edu/faculty/bio/zhengyuan-zhou">Zhengyuan Zhou</a></p>
<p><a href="01/2023">01/2023</a> Four papers accepted at AISTATS 2023:</p>
<ul>
<li><p>Zihan Wang, Jason Lee, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2212.03714">&lsquo;&lsquo;Reconstructing Training Data from Model Gradient, Provably"</a></p>
</li>
<li><p>Shuo Yang, Yijun Dong, Rachel Ward, Inderjit Dhillon, Sujay Sanghavi, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2202.12230">&lsquo;&lsquo;Sample Efficiency of Data Augmentation Consistency Regularization"</a></p>
</li>
<li><p>Kurtland Chua, <b>Qi Lei</b>, Jason Lee. <a href="https://arxiv.org/abs/2110.09507">&lsquo;&lsquo;Provable Hierarchy-Based Meta-Reinforcement Learning"</a></p>
</li>
<li><p>Qian Yu, Yining Wang, Baihe Huang, <b>Qi Lei</b>, Jason Lee. <a href="https://proceedings.mlr.press/v206/yu23a/yu23a.pdf">&lsquo;&lsquo;Optimal Sample Complexity Bounds for Non-convex Optimization under Kurdyka-Lojasiewicz Condition"</a></p>
</li>
</ul>
<p><a href="01/2023">01/2023</a> Invited talk at <a href="https://slowdnn-workshop.github.io/schedule/">SLowDNN</a> on <a href="https://arxiv.org/abs/2212.03714">reconstruction attack with guarantees</a></p>
<p><a href="12/2022">12/2022</a> Organized the <a href="https://meta-learn.github.io/2022/">workshop on meta-learning</a> at NeurIPS 2022</p>
<p><a href="09/2022">09/2022</a> Presented the a unified view on <a href="https://arxiv.org/abs/2008.01064">reconstruction-based and similarity-based self-supervised learning</a> in <a href="https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=74398">SIAM-MDS</a></p>
<p><a href="09/2022">09/2022</a> Started a new journey as an assistant professor of Courant Math/CDS at NYU!</p>
<h2>Selected Papers</h2>
<p>(<a href="papers.html">full publication list</a>)</p>
<p>7. Zihan Wang, Jason Lee, <b>Qi Lei</b>.
<a href="https://arxiv.org/abs/2212.03714">&ldquo;Reconstructing Training Data from Model Gradient, Provably&rdquo;</a>, AISTATS 2023</p>
<p>6. Baihe Huang*, Kaixuan Huang*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*, Runzhe Wang*, and Jiaqi Yang*.
<a href="https://arxiv.org/abs/2107.04518">&ldquo;Optimal Gradient-based Algorithms for Non-concave Bandit Optimization&rdquo;</a>, NeurIPS 2021</p>
<p>5. Jason D. Lee*, <b>Qi Lei</b>*, Nikunj Saunshi*, Jiacheng Zhuo*. <a href="https://arxiv.org/abs/2008.01064">&ldquo;Predicting What You Already Know Helps: Provable Self-Supervised Learning&rdquo;</a>, NeurIPS 2021</p>
<p>4. Simon S. Du*, Wei Hu*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*.  <a href="https://arxiv.org/abs/2002.09434">&ldquo;Few-Shot Learning via Learning the Representation, Provably&rdquo;</a>, <i>The International Conference on Learning Representations (ICLR) 2021</i></p>
<p>3. <b>Qi Lei</b>, Jason D. Lee, Alexandros G. Dimakis, Constantinos Daskalakis. <a href="https://arxiv.org/abs/1910.07030">&ldquo;SGD Learns One-Layer Networks in WGANs&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML) 2020</i></p>
<p>2. <b>Qi Lei</b>*, Lingfei Wu*, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S. Dhillon, Michael Witbrock. <a href="https://arxiv.org/abs/1812.00151">&ldquo;Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification&rdquo;</a>, <i>Systems and Machine Learning (sysML). 2019</i> <a href="https://github.com/cecilialeiqi/adversarial_text">(code</a>, <a href="discrete_attack.pdf">slides)</a> </p>
<ul>
<li><p>Press coverage: <a href="https://www.nature.com/articles/d41586-019-01510-1?utm_source=twt_nnc&amp;utm_medium=social&amp;utm_campaign=naturenews&amp;sf212595612=1">&lt;Nature Story&gt;</a> <a href="https://venturebeat.com/2019/04/01/text-based-ai-models-are-vulnerable-to-paraphrasing-attacks-researchers-find/">&lt;Vecturebeat&gt;</a> <a href="https://bdtechtalks.com/2019/04/02/ai-nlp-paraphrasing-adversarial-attacks/">&lt;Tech Talks&gt;</a> <a href="https://www.jiqizhixin.com/articles/2019-03-27-10?from=synced&amp;keyword=SysML%202019">&lt;机器之心&gt;</a></p>
</li>
</ul>
<p>1. Rashish Tandon, <b>Qi Lei</b>, Alexandros G. Dimakis, Nikos Karampatziakis, <a href="https://arxiv.org/abs/1612.03301">&ldquo;Gradient Coding: Avoiding Stragglers in Distributed Learning&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML), 2017</i> <a href="https://github.com/rashisht1/gradient_coding">(code)</a></p>
<div id="footer">
<div id="footer-text">
Page generated 2024-01-08 14:26:57 China Standard Time, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
