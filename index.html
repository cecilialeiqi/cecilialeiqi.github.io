<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EDFDR7C0C6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-EDFDR7C0C6');
</script>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Qi Lei (雷琦)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html" class="current">Main</a></div>
<div class="menu-item"><a href="bio.html">Bio&nbsp;and&nbsp;CV</a></div>
<div class="menu-item"><a href="contact.html">Contact</a></div>
<div class="menu-item"><a href="teaching.html">DS-GA3001</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="papers.html">Publication&nbsp;List</a></div>
<div class="menu-item"><a href="https://github.com/cecilialeiqi/">Github</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Qi Lei (雷琦)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="Qi Lei.jpg"><img src="Qi Lei.jpg" alt="Qi Lei NYU" width="173px" height="225px" /></a>&nbsp;</td>
<td align="left"><p>Assistant Professor of Mathematics and Data Science, and, by courtesy,<br />
Assistant Professor of Computer Science,<br />
Member of <a href="https://wp.nyu.edu/cilvr/">CILVR lab</a>,<br />
Member of <a href="https://mad.cds.nyu.edu/">Math and Data</a>,<br />
<a href="https://www.courant.nyu.edu/">Courant Institute of Mathematical Sciences</a> and <a href="https://cds.nyu.edu/">Center for Data Science</a>,<br />
<a href="https://www.nyu.edu/">New York University</a></p>
<p>Email: ql518 at nyu.edu</p>
</td></tr></table>
<h2>Research Overview</h2>
<p>My research interests are <b>machine learning</b>, <b>deep learning</b>, and <b>optimization</b>. Specifically, I am interested in developing sample- and computationally efficient algorithms for some fundamental machine learning problems. </p>
<p>Recent research highlights: <a href="https://cecilialeiqi.github.io/JSM_pruning_talk.pdf">(LLM Pruning)</a> <a href="https://cecilialeiqi.github.io/data_reconstruction_slides.pdf">(Data Reconstruction Attack and Defense)</a>, <a href="https://cecilialeiqi.github.io/job_talk.pdf">(Theoretical Foundations of Pre-trained Models)</a></p>
<p>(<a href="cv_2.pdf">Curriculum Vitae</a>, <a href="https://github.com/cecilialeiqi/">Github</a>, <a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&amp;hl=en">Google Scholar</a>)</p>
<h2>Advertisement</h2>
<p>I am actively looking for self-motivated and proactive students to work with. You are welcome to shoot me an email with your CV and short research plans/interests. (You may refer to this <a href="https://docs.google.com/document/d/1D1qBdVsTXb4VF18uAO2OfMRq9NNGTtkb3Lx2UYE3HS4/edit?usp=sharing">link</a> to see whether our research interests match.) </p>
<p>For Ph.D. applicants, please apply to <a href="https://math.nyu.edu/dynamic/graduate/phd-mathematics/admission-policies/">Courant Mathematics</a> or <a href="https://cds.nyu.edu/phd-program/">Center for Data Science</a> whichever you see fit and mention my name in your application. I do not plan to admit students from Courant CS for now.</p>
<p>For prospective students or interns who want to work with me in short term, please fill out <a href="https://forms.gle/bfV5598RaBkrEvMi7">this form</a> so that we could find a suitable project for you. </p>
<p>For prospective post-doc applicants, I encourage you to apply for the positions of <a href="https://cds.nyu.edu/fellowsjobs/">CDS Faculty Fellows</a>, <a href="https://math.nyu.edu/dynamic/research/postdoctoral-and-visitor-programs/">Courant Instructors</a>, and <a href="https://www.simonsfoundation.org/grant/flatiron-research-fellow-opportunities/">Flatiron Research Fellows</a>. </p>
<h2>News and Announcement</h2>
<p><a href="08/2024">08/2024</a> Invited talk at <a href="https://ww3.aievolution.com/JSMAnnual2024/index.cfm?do=ev.viewEv&amp;ev=2372">JSM Harnessing Large Language Models: Opportunities and Challenges for Statistics</a> on <a href="https://cecilialeiqi.github.io/JSM_pruning_talk.pdf">LLM Pruning</a>  </p>
<p><a href="06/2024">06/2024</a> Invited talk at <a href="https://www.birs.ca/events/2024/5-day-workshops/24w5297">Mathematics of Deep Learning</a> on <a href="https://cecilialeiqi.github.io/data_reconstruction_slides.pdf">Data Reconstruction Error Analysis</a></p>
<p><a href="05/2024">05/2024</a> Two papers accepted at ICML 2024:</p>
<ul>
<li><p>Hoang Phan, Andrew Gordon Wilson, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2403.02695">Controllable Prompt Tuning For Balancing Group Distributional Robustness</a></p>
</li>
<li><p>Hong Jun Jeon, Jason D Lee, <b>Qi Lei</b>, Benjamin Van Roy. <a href="https://arxiv.org/abs/2401.15530">An Information-Theoretic Analysis of In-Context Learning</a></p>
</li>
</ul>
<p><a href="04/2024">04/2024</a> Congratulations to my Capstone team Christine Gao, Ciel Wang and Yuqi Zhang on winning the <a href="https://cds.nyu.edu/capstone-project/">Best Student Voted Runner-Up Poster</a> (out of 46 projects!) with their great work on <a href="https://cecilialeiqi.github.io/CapstonePoster.pdf">Medical Data Leakage with Multi-site Collabrative Training</a></p>
<p><a href="03/2024">03/2024</a> Invited talk at the <a href="https://ee-ciss.princeton.edu/">CISS 24@Princeton</a> on data reconstruction attack and defense <a href="https://cecilialeiqi.github.io/privacy_ciss.pdf">(slides)</a></p>
<p><a href="03/2024">03/2024</a> New papers out:</p>
<ul>
<li><p><a href="https://arxiv.org/pdf/2402.09478">Data Reconstruction Attacks and Defenses: A Systematic Evaluation</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2403.06424">Bridging Domains with Approximately Shared Features</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2403.02695">Controllable Prompt Tuning For Balancing Group Distributional Robustness</a></p>
</li>
</ul>
<p><a href="01/2024">01/2024</a> New papers out:</p>
<ul>
<li><p><a href="https://arxiv.org/pdf/2312.05720">Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer Inputs of Language Models in Federated Learning</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2401.15530">An Information-Theoretic Analysis of In-Context Learning</a></p>
</li>
</ul>
<p><a href="01/2024">01/2024</a> Presented our recent paper <a href="https://openreview.net/pdf?id=MlgnGWdqWl">Exploring Minimally Sufficient Representation in
Active Learning through Label-Irrelevant Patch
Augmentation</a><a href="https://cecilialeiqi.github.io/CPAL_active_learning.pdf">(slides)</a> at <a href="https://cpal.cc/">CPAL2024</a></p>
<p><a href="10/2023">10/2023</a> I am a co-PI on the <a href="https://rome.cims.nyu.edu/">ROME: Reduced Modeling with Extreme Data project</a>, a Department of Energy project developing Science Foundations for Energy Earthshots. More information is in the <a href="https://www.energy.gov/articles/doe-announces-264-million-basic-research-support-energy-earthshotstm">DOE press release</a>.</p>
<p><a href="10/2023">10/2023</a> Two papers (1 main + 1 findings) accepted at EMNLP 2023:</p>
<ul>
<li><p>Jianwei Li, <b>Qi Lei</b>, Wei Cheng, Dongkuan Xu. <a href="https://arxiv.org/abs/2310.13191">&lsquo;&lsquo;Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models"</a></p>
</li>
<li><p>Jianwei Li, Weizhi Gao, <b>Qi Lei</b>, Dongkuan Xu. <a href="https://arxiv.org/abs/2310.13183">&lsquo;&lsquo;Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection"</a> </p>
</li>
</ul>
<p><a href="09/2023">09/2023</a> Two papers accepted at Neurips 2023:</p>
<ul>
<li><p>Yijun Dong, Kevin Miller, <b>Qi Lei</b>, Rachel Ward. <a href="https://arxiv.org/pdf/2307.11030">&lsquo;&lsquo;Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering"</a></p>
</li>
<li><p>Qian Yu, Yining Wang, Baihe Huang, <b>Qi Lei</b>, Jason D. Lee. <a href="https://arxiv.org/pdf/2306.12383">&lsquo;&lsquo;Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms"</a></p>
</li>
</ul>
<p><a href="08/2023">08/2023</a> Won the <a href="https://www.nyu.edu/content/dam/nyu/provost/documents/Research/2017_Whitehead_Fellowship.pdf">Whitehead Fellowship for Junior Faculty in Biomedical and Biological Sciences</a></p>
<p><a href="06/2023">06/2023</a> New papers out:</p>
<ul>
<li><p><a href="https://arxiv.org/pdf/2307.11030">Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/2306.12383">Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms</a></p>
</li>
</ul>
<h2>Selected Papers</h2>
<p>(<a href="papers.html">full publication list</a>)</p>
<p>7. Zihan Wang, Jason Lee, <b>Qi Lei</b>.
<a href="https://arxiv.org/abs/2212.03714">&ldquo;Reconstructing Training Data from Model Gradient, Provably&rdquo;</a>, AISTATS 2023</p>
<p>6. Baihe Huang*, Kaixuan Huang*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*, Runzhe Wang*, and Jiaqi Yang*.
<a href="https://arxiv.org/abs/2107.04518">&ldquo;Optimal Gradient-based Algorithms for Non-concave Bandit Optimization&rdquo;</a>, NeurIPS 2021</p>
<p>5. Jason D. Lee*, <b>Qi Lei</b>*, Nikunj Saunshi*, Jiacheng Zhuo*. <a href="https://arxiv.org/abs/2008.01064">&ldquo;Predicting What You Already Know Helps: Provable Self-Supervised Learning&rdquo;</a>, NeurIPS 2021</p>
<p>4. Simon S. Du*, Wei Hu*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*.  <a href="https://arxiv.org/abs/2002.09434">&ldquo;Few-Shot Learning via Learning the Representation, Provably&rdquo;</a>, <i>The International Conference on Learning Representations (ICLR) 2021</i></p>
<p>3. <b>Qi Lei</b>, Jason D. Lee, Alexandros G. Dimakis, Constantinos Daskalakis. <a href="https://arxiv.org/abs/1910.07030">&ldquo;SGD Learns One-Layer Networks in WGANs&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML) 2020</i></p>
<p>2. <b>Qi Lei</b>*, Lingfei Wu*, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S. Dhillon, Michael Witbrock. <a href="https://arxiv.org/abs/1812.00151">&ldquo;Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification&rdquo;</a>, <i>Systems and Machine Learning (sysML). 2019</i> <a href="https://github.com/cecilialeiqi/adversarial_text">(code</a>, <a href="discrete_attack.pdf">slides)</a> </p>
<ul>
<li><p>Press coverage: <a href="https://www.nature.com/articles/d41586-019-01510-1?utm_source=twt_nnc&amp;utm_medium=social&amp;utm_campaign=naturenews&amp;sf212595612=1">&lt;Nature Story&gt;</a> <a href="https://venturebeat.com/2019/04/01/text-based-ai-models-are-vulnerable-to-paraphrasing-attacks-researchers-find/">&lt;Vecturebeat&gt;</a> <a href="https://bdtechtalks.com/2019/04/02/ai-nlp-paraphrasing-adversarial-attacks/">&lt;Tech Talks&gt;</a> <a href="https://www.jiqizhixin.com/articles/2019-03-27-10?from=synced&amp;keyword=SysML%202019">&lt;机器之心&gt;</a></p>
</li>
</ul>
<p>1. Rashish Tandon, <b>Qi Lei</b>, Alexandros G. Dimakis, Nikos Karampatziakis, <a href="https://arxiv.org/abs/1612.03301">&ldquo;Gradient Coding: Avoiding Stragglers in Distributed Learning&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML), 2017</i> <a href="https://github.com/rashisht1/gradient_coding">(code)</a></p>
<div id="footer">
<div id="footer-text">
Page generated 2024-08-14 15:54:19 Eastern Daylight Time, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
