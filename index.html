<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Qi Lei (雷琦)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html" class="current">Main</a></div>
<div class="menu-item"><a href="bio.html">Bio&nbsp;and&nbsp;CV</a></div>
<div class="menu-item"><a href="contact.html">Contact</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
<div class="menu-item"><a href="teaching.html">DS-GA3001</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="papers.html">Publication&nbsp;List</a></div>
<div class="menu-item"><a href="https://github.com/cecilialeiqi/">Github</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Qi Lei (雷琦)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="Qi Lei.jpg"><img src="Qi Lei.jpg" alt="Qi Lei NYU" width="173px" height="225px" /></a>&nbsp;</td>
<td align="left"><p>Assistant Professor of Mathematics and Data Science, and, by courtesy,<br />
Assistant Professor of Computer Science,<br />
Member of <a href="https://wp.nyu.edu/cilvr/">CILVR lab</a>,<br />
Member of <a href="https://mad.cds.nyu.edu/">Math and Data</a>,<br />
Google DeepMind Faculty,<br />
<a href="https://www.courant.nyu.edu/">Courant Institute of Mathematical Sciences</a> and <a href="https://cds.nyu.edu/">Center for Data Science</a>,<br />
<a href="https://www.nyu.edu/">New York University</a></p>
<p>Email: ql518 at nyu.edu</p>
</td></tr></table>
<h2>Research Overview</h2>
<p>My research aims to <b>bridge the theoretical and empirical boundary of modern machine learning algorithms</b> and in particular <b>AI safety</b>, with a focus on <i>data privacy</i>, <i>distributionally robust algorithms</i>, <i>sample- and parameter-efficient learning</i>. </p>
<p>Recent research highlights: <a href="https://cecilialeiqi.github.io/weak-2-strong-FSML.pdf">(Weak-to-Strong Generalization)</a>, <a href="https://cecilialeiqi.github.io/data_reconstruction_slides.pdf">(Data Reconstruction Attack and Defense)</a>, <a href="https://cecilialeiqi.github.io/data_model_pruning.pdf">(Data and Model Pruning)</a>, <a href="https://cecilialeiqi.github.io/job_talk.pdf">(Theoretical Foundations of Pre-trained Models)</a></p>
<p>(<a href="cv_2.pdf">Curriculum Vitae</a>, <a href="https://github.com/cecilialeiqi/">Github</a>, <a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&amp;hl=en">Google Scholar</a>)</p>
<h2>Advertisement</h2>
<p>I am actively looking for self-motivated and proactive students to work with. You are welcome to shoot me an email with your CV and short research plans/interests. (You may refer to this <a href="https://docs.google.com/document/d/1D1qBdVsTXb4VF18uAO2OfMRq9NNGTtkb3Lx2UYE3HS4/edit?usp=sharing">link</a> to see whether our research interests match.) </p>
<p>For Ph.D. applicants, please apply to <a href="https://math.nyu.edu/dynamic/graduate/phd-mathematics/admission-policies/">Courant Mathematics</a> or <a href="https://cds.nyu.edu/phd-program/">Center for Data Science</a> whichever you see fit and mention my name in your application. I do not plan to admit students from Courant CS for now.</p>
<p>For prospective post-doc applicants, I encourage you to apply for the positions of <a href="https://cds.nyu.edu/fellowsjobs/">CDS Faculty Fellows</a>, <a href="https://math.nyu.edu/dynamic/research/postdoctoral-and-visitor-programs/">Courant Instructors</a>, and <a href="https://www.simonsfoundation.org/flatiron/careers/?tab=job-openings&amp;center=ccm">Flatiron Research Fellows</a>. </p>
<h2>News and Announcement</h2>
<p><a href="08/2025">08/2025</a> Invited talk at <a href="https://fsmlims.wixsite.com/fsml25">the Inaugural Workshop on Frontiers in Statistical Machine Learning</a> on <a href="https://cecilialeiqi.github.io/weak-2-strong-FSML.pdf">Weak-to-Strong Generalization</a></p>
<p><a href="07/2025">07/2025</a> Invited talk at <a href="https://web.cvent.com/event/0fc81644-f4d8-416b-84d3-be802f613f7a/summary">Inverse Methods for Complex Systems under Uncertainty Workshop</a> on <a href="https://cecilialeiqi.github.io/flash_talk.pdf">Data Reconstruction Attacks in AI models are Inverse Problems</a></p>
<p><a href="05/2025">05/2025</a> Paper accepted at UAI 2025:</p>
<ul>
<li><p>Tianci Liu, Tong Yang, Quan Zhang, <b>Qi Lei</b>. <a href="https://openreview.net/forum?id=3uK3fLpjtD">Beyond Invisibility: Learning Robust Visible Watermarks for Stronger Copyright Protection</a></p>
</li>
</ul>
<p><a href="05/2025">05/2025</a> Paper accepted at ICML 2025:</p>
<ul>
<li><p>Yijun Dong, Yicheng Li, Yunai Li, Jason D Lee, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2502.05075">Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension</a></p>
</li>
</ul>
<p><a href="01/2025">01/2025</a> Three papers accepted at AISTATS 2025:</p>
<ul>
<li><p>Sheng Liu, Zihan Wang, Yuxiao Chen, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2402.09478">Data Reconstruction Attacks and Defenses: A Systematic Evaluation</a></p>
</li>
<li><p>Tao Wen, Zihan Wang, Quan Zhang, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2502.09850">Elastic Representation: Mitigating Spurious Correlations for Group Robustness</a></p>
</li>
<li><p>Ziliang Samuel Zhong, Xiang Pan, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2403.06424">Bridging Domains with Approximately Shared Features</a></p>
</li>
</ul>
<p><a href="01/2025">01/2025</a> Paper accepted at ICLR 2025: </p>
<ul>
<li><p>Qi Zhang, Yifei Wang, Jingyi Cui, Xiang Pan, <b>Qi Lei</b>, Stefanie Jegelka, Yisen Wang. <a href="https://arxiv.org/abs/2410.21331">Beyond Interpretability: The Gains of Feature Monosemanticity on Model Robustness</a></p>
</li>
</ul>
<p><a href="01/2025">01/2025</a> Invited talk at <a href="https://ims.nus.edu.sg/">IMS@NUS</a> on <a href="https://cecilialeiqi.github.io/data_reconstruction_error_icsds.pdf">Theoretical Bounds of Data Reconstruction Error and Induced Optimal Defenses (slides)</a> </p>
<p><a href="12/2024">12/2024</a> Invited talk at ICSDS on <a href="https://cecilialeiqi.github.io/data_reconstruction_error_icsds.pdf">Theoretical Bounds of Data Reconstruction Error and Induced Optimal Defenses (slides)</a></p>
<p><a href="11/2024">11/2024</a> Invited talk at Harvard Statistics on <a href="https://cecilialeiqi.github.io/data_model_pruning.pdf">Distribution-aware Data and Model Pruning (slides)</a></p>
<p><a href="10/2024">10/2024</a> Organized the minisymposium <a href="https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=80554">“Efficient Computation and Learning with Randomized Sampling and Pruning”</a> at SIAM MDS 2024 </p>
<p><a href="09/2024">09/2024</a> Two papers accepted at NeurIPS:</p>
<ul>
<li><p>Yijun Dong, Hoang Phan, Xiang Pan, <b>Qi Lei</b>. <a href="https://arxiv.org/abs/2407.06120">Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning</a></p>
</li>
<li><p>Qian Yu, Yining Wang, Baihe Huang, <b>Qi Lei</b>, Jason D Lee. <a href="https://arxiv.org/abs/2406.19617">Stochastic Zeroth-Order Optimization under Strongly Convexity and Lipschitz Hessian: Minimax Sample Complexity</a></p>
</li>
</ul>
<h2>Selected Papers</h2>
<p>(<a href="papers.html">full publication list</a>)</p>
<p>8. Yijun Dong, Yicheng Li, Yunai Li, Jason D Lee, <b>Qi Lei</b>, <a href="https://arxiv.org/abs/2502.05075">Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension</a>, to appear at ICML 2025</p>
<p>7. Sheng Liu*, Zihan Wang*, Yuxiao Chen, <b>Qi Lei</b>, <a href="https://arxiv.org/pdf/2402.09478">&ldquo;Data Reconstruction Attacks and Defenses: A Systematic
Evaluation&rdquo;</a>, AISTATS 2025</p>
<p>6. Zihan Wang, Jason Lee, <b>Qi Lei</b>.
<a href="https://arxiv.org/abs/2212.03714">&ldquo;Reconstructing Training Data from Model Gradient, Provably&rdquo;</a>, AISTATS 2023</p>
<p>5. Baihe Huang*, Kaixuan Huang*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*, Runzhe Wang*, and Jiaqi Yang*.
<a href="https://arxiv.org/abs/2107.04518">&ldquo;Optimal Gradient-based Algorithms for Non-concave Bandit Optimization&rdquo;</a>, NeurIPS 2021</p>
<p>4. Jason D. Lee*, <b>Qi Lei</b>*, Nikunj Saunshi*, Jiacheng Zhuo*. <a href="https://arxiv.org/abs/2008.01064">&ldquo;Predicting What You Already Know Helps: Provable Self-Supervised Learning&rdquo;</a>, NeurIPS 2021</p>
<p>3. Simon S. Du*, Wei Hu*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*.  <a href="https://arxiv.org/abs/2002.09434">&ldquo;Few-Shot Learning via Learning the Representation, Provably&rdquo;</a>, <i>The International Conference on Learning Representations (ICLR) 2021</i></p>
<p>2. <b>Qi Lei</b>*, Lingfei Wu*, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S. Dhillon, Michael Witbrock. <a href="https://arxiv.org/abs/1812.00151">&ldquo;Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification&rdquo;</a>, <i>Systems and Machine Learning (sysML). 2019</i> <a href="https://github.com/cecilialeiqi/adversarial_text">(code</a>, <a href="discrete_attack.pdf">slides)</a> </p>
<ul>
<li><p>Press coverage: <a href="https://www.nature.com/articles/d41586-019-01510-1?utm_source=twt_nnc&amp;utm_medium=social&amp;utm_campaign=naturenews&amp;sf212595612=1">&lt;Nature Story&gt;</a> <a href="https://venturebeat.com/2019/04/01/text-based-ai-models-are-vulnerable-to-paraphrasing-attacks-researchers-find/">&lt;Vecturebeat&gt;</a> <a href="https://bdtechtalks.com/2019/04/02/ai-nlp-paraphrasing-adversarial-attacks/">&lt;Tech Talks&gt;</a> <a href="https://www.jiqizhixin.com/articles/2019-03-27-10?from=synced&amp;keyword=SysML%202019">&lt;机器之心&gt;</a></p>
</li>
</ul>
<p>1. Rashish Tandon, <b>Qi Lei</b>, Alexandros G. Dimakis, Nikos Karampatziakis, <a href="https://arxiv.org/abs/1612.03301">&ldquo;Gradient Coding: Avoiding Stragglers in Distributed Learning&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML), 2017</i> <a href="https://github.com/rashisht1/gradient_coding">(code)</a></p>
<div id="footer">
<div id="footer-text">
Page generated 2025-09-13 11:04:32 , by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
