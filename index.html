<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Qi Lei (雷琦)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html" class="current">Main</a></div>
<div class="menu-item"><a href="bio.html">Bio&nbsp;and&nbsp;CV</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="papers.html">Publication&nbsp;List</a></div>
<div class="menu-item"><a href="https://github.com/cecilialeiqi/">Github</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Qi Lei (雷琦)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="Qi Lei.jpg"><img src="Qi Lei.jpg" alt="Qi Lei UT Austin" width="110px" height="150px" /></a>&nbsp;</td>
<td align="left"><p>Email: qilei at princeton.edu
</p>
<p>Website: <a href="cecilialeiqi.github.io" target=&ldquo;blank&rdquo;>http://cecilialeiqi.github.io</a>
</p>
</td></tr></table>
<p>I am a postdoc research associate at EE, Princeton University. I am fortunate to have Prof. <a href="http://jasondlee88.github.io" target=&ldquo;blank&rdquo;>Jason Lee</a> as my research mentor. I received my Ph.D. from <a href="https://www.oden.utexas.edu/" target=&ldquo;blank&rdquo;>Oden Institute for Computational Engineering and Sciences</a>, 
University of Texas at Austin, advised by <a href="http://users.ece.utexas.edu/~dimakis/index.html" target=&ldquo;blank&rdquo;>Alexandros G. Dimakis</a> and <a href="http://www.cs.utexas.edu/~inderjit/" target=&ldquo;blank&rdquo;>Inderjit S. Dhillon</a>. 
I was also a member of <a href="http://bigdata.ices.utexas.edu/" target=&ldquo;blank&rdquo;>Center for Big Data Analytics</a> and <a href="https://wncg.org/" target=&ldquo;blank&rdquo;>Wireless Networking &amp; Communications Group</a>. I visited <a href="https://www.ias.edu/" target=&ldquo;blank&rdquo;>IAS</a> for the <a href="http://www.math.ias.edu/theoretical_machine_learning" target=&ldquo;blank&rdquo;>Theoretical Machine Learning program</a> from September 2019 to July 2020. Prior to that, I was a Research Fellow at the Simons Institute for the Theory of Computing at UC Berkeley for the program on Foundations of Deep Learning.
</p>
<p>My research interests are <b>machine learning</b>, <b>deep learning</b> and <b>optimization</b>. Specifically, I'm interested in developing provably efficient and robust algorithms for some fundamental machine learning problems. 
</p>
<p>(<a href="cv_2.pdf" target=&ldquo;blank&rdquo;>Curriculum Vitae</a>, <a href="https://github.com/cecilialeiqi/" target=&ldquo;blank&rdquo;>Github</a>, <a href="https://scholar.google.com/citations?user=kGOgaowAAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>Google Scholar</a>)
</p>
<h2>News and Announcement</h2>
<p><a href="05/2021" target=&ldquo;blank&rdquo;>05/2021</a> Three papers are accepted at ICML 2021:
</p>
<ul>
<li><p><b>Qi Lei</b>, Wei Hu, Jason D. Lee. &lsquo;&lsquo;Near-Optimal Linear Regression under Distribution Shift"
</p>
</li>
<li><p>Tianle Cai*, Ruiqi Gao*, Jason D Lee*, <b>Qi Lei</b>*.  <a href="https://arxiv.org/abs/2102.11203" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;A Theory of Label Propagation for Subpopulation Shift"</a>
</p>
</li>
<li><p>Jay Whang, <b>Qi Lei</b>, Alexandros G. Dimakis. &lsquo;&lsquo;Solving Inverse Problems with a Flow-based Noise Model"
</p>
</li>
</ul>
<p><a href="05/2021" target=&ldquo;blank&rdquo;>05/2021</a> I'm invited to give a talk on <a href="https://cms.caltech.edu/events/90169" target=&ldquo;blank&rdquo;>Provable Representation Learning</a> at <a href="https://eas.caltech.edu/young_investigators" target=&ldquo;blank&rdquo;>Caltech Young Investigators Lecture</a>
</p>
<p><a href="05/2021" target=&ldquo;blank&rdquo;>05/2021</a> New paper out:
<a href="https://arxiv.org/abs/2105.02221" target=&ldquo;blank&rdquo;>How Fine-Tuning Allows for Effective Meta-Learning</a>
</p>
<p><a href="03/2021" target=&ldquo;blank&rdquo;>03/2021</a> My PhD thesis <a href="https://cecilialeiqi.github.io/LEI-DISSERTATION-2020.pdf" target=&ldquo;blank&rdquo;>Provably Effective Algorithms for Min-Max Optimization</a> won this year's <a href="https://www.oden.utexas.edu/about/news/qi-lei-wins-Outstanding-Dissertation-Award/" target=&ldquo;blank&rdquo;>Oden Institute Outstanding Dissertation Award</a> 
</p>
<p><a href="01/2021" target=&ldquo;blank&rdquo;>01/2021</a> Our paper is accepted at AISTATS 2021:
</p>
<ul>
<li><p><b>Qi Lei</b>*, Sai Ganesh Nagarajan*, Ioannis Panageas*, Xiao Wang*. &ldquo;Last iterate convergence in no-regret learning: constrained min-max optimization for convex-concave landscapes&rdquo;
</p>
</li>
</ul>
<p><a href="01/2021" target=&ldquo;blank&rdquo;>01/2021</a> Our paper is accepted at ICLR 2021:
</p>
<ul>
<li><p>Simon S. Du*, Wei Hu*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*. &ldquo;Few-Shot Learning via Learning the Representation, Provably&rdquo;
</p>
</li>
</ul>
<p><a href="12/2020" target=&ldquo;blank&rdquo;>12/2020</a> I'm invited to give a talk on <a href="https://simons.berkeley.edu/talks/sgd-learns-one-layer-networks-wgans" target=&ldquo;blank&rdquo;>SGD learns one-layer network with WGANs</a> at <a href="https://simons.berkeley.edu/workshops/hd-2020-3" target=&ldquo;blank&rdquo;>Learning and Testing in High Dimensions</a>
</p>
<p><a href="11/2020" target=&ldquo;blank&rdquo;>11/2020</a> I'm invited to give a Young Researcher Spotlight Talk at the <a href="https://sites.google.com/view/slowdnn/" target=&ldquo;blank&rdquo;>&ldquo;Seeking Low-dimensionality in Deep Learning&rdquo;</a> workshop on my recent work of <a href="https://www.youtube.com/watch?v=SvddIPXjNDU&amp;list=PL7P834wcUN3eSh7Nn4wzPBjEnme4Rls7n&amp;index=15&amp;ab_channel=SLowDNNWorkshop" target=&ldquo;blank&rdquo;>provable representation learning</a>
</p>
<p><a href="10/2020" target=&ldquo;blank&rdquo;>10/2020</a> I'm invited to give a talk on <a href="https://www.youtube.com/watch?v=5A1iKkPv1Y0&amp;feature=youtu.be&amp;ab_channel=Oneworldtheoreticalmachinelearning" target=&ldquo;blank&rdquo;>provable self-supervised learning</a> at <a href="https://www.oneworldml.org/" target=&ldquo;blank&rdquo;>One-World ML seminar</a> 
</p>
<p><a href="10/2020" target=&ldquo;blank&rdquo;>10/2020</a> Our paper is accepted at NeurIPS 2020: 
</p>
<ul>
<li><p>Xiao Wang, <b>Qi Lei</b>, Ioannis Panageas.  &ldquo;Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet Log-Sobolev&rdquo;
</p>
</li>
</ul>
<p><a href="09/2020" target=&ldquo;blank&rdquo;>09/2020</a> I am selected as a 2020 Computing Innovation Fellow. Thank you CRA! 
</p>
<p><a href="08/2020" target=&ldquo;blank&rdquo;>08/2020</a> New paper out:
</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2008.01064" target=&ldquo;blank&rdquo;>&ldquo;Predicting What You Already Know Helps: Provable Self-Supervised Learning&rdquo;</a>
</p>
</li>
</ul>
<p><a href="06/2020" target=&ldquo;blank&rdquo;>06/2020</a> Our paper is accepted at ICML 2020: 
</p>
<ul>
<li><p><b>Qi Lei</b>, Jason D. Lee, Alexandros G. Dimakis, Constantinos Daskalakis. <a href="https://arxiv.org/abs/1910.07030" target=&ldquo;blank&rdquo;>&ldquo;SGD Learns One-Layer Networks in WGANs&rdquo;</a> 
</p>
</li>
</ul>
<h2>Selected Papers</h2>
<p>(<a href="papers.html" target=&ldquo;blank&rdquo;>full publication list</a>)
</p>
<p>7. Jason D. Lee*, <b>Qi Lei</b>*, Nikunj Saunshi*, Jiacheng Zhuo*. <a href="https://arxiv.org/abs/2008.01064" target=&ldquo;blank&rdquo;>&ldquo;Predicting What You Already Know Helps: Provable Self-Supervised Learning&rdquo;</a>, <i>arxiv preprint</i>
</p>
<p>6. Simon S. Du*, Wei Hu*, Sham M. Kakade*, Jason D. Lee*, <b>Qi Lei</b>*.  <a href="https://arxiv.org/abs/2002.09434" target=&ldquo;blank&rdquo;>&ldquo;Few-Shot Learning via Learning the Representation, Provably&rdquo;</a>, <i>arxiv preprint</i>
</p>
<p>5. <b>Qi Lei</b>, Jason D. Lee, Alexandros G. Dimakis, Constantinos Daskalakis. <a href="https://arxiv.org/abs/1910.07030" target=&ldquo;blank&rdquo;>&ldquo;SGD Learns One-Layer Networks in WGANs&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML) 2020</i>
</p>
<p>4. <b>Qi Lei</b>, Jiacheng Zhuo, Constantine Caramanis, Inderjit S Dhillon, Alexandros G Dimakis. <a href="https://arxiv.org/abs/1906.02436" target=&ldquo;blank&rdquo;>&ldquo;Primal-Dual Block Frank-Wolfe&rdquo;</a>, <i> Proc. of Neural Information Processing Systems (NeurIPS) 2019</i> (<a href="PDBFW.pdf" target=&ldquo;blank&rdquo;>slides</a>, <a href="https://github.com/CarlsonZhuo/primal_dual_frank_wolfe" target=&ldquo;blank&rdquo;>code</a>)
</p>
<p>3. <b>Qi Lei</b>, Ajil Jalal, Inderjit S. Dhillon, Alexandros G. Dimakis. <a href="https://arxiv.org/abs/1906.07437" target=&ldquo;blank&rdquo;>&ldquo;Inverting Deep Generative models, One layer at a time&rdquo;</a>, <i> Proc. of Neural Information Processing Systems (NeurIPS) 2019</i> (<a href="invert_GAN_poster.pdf" target=&ldquo;blank&rdquo;>poster</a>, <a href="https://github.com/cecilialeiqi/InvertGAN_LP" target=&ldquo;blank&rdquo;>code</a>)
</p>
<p>2. <b>Qi Lei</b>*, Lingfei Wu*, Pin-Yu Chen, Alexandros G. Dimakis, Inderjit S. Dhillon, Michael Witbrock. <a href="https://arxiv.org/abs/1812.00151" target=&ldquo;blank&rdquo;>&ldquo;Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification&rdquo;</a>, <i>Systems and Machine Learning (sysML). 2019</i> <a href="https://github.com/cecilialeiqi/adversarial_text" target=&ldquo;blank&rdquo;>(code</a>, <a href="discrete_attack.pdf" target=&ldquo;blank&rdquo;>slides)</a> 
</p>
<ul>
<li><p>Press coverage: <a href="https://www.nature.com/articles/d41586-019-01510-1?utm_source=twt_nnc&amp;utm_medium=social&amp;utm_campaign=naturenews&amp;sf212595612=1" target=&ldquo;blank&rdquo;>&lt;Nature Story&gt;</a> <a href="https://venturebeat.com/2019/04/01/text-based-ai-models-are-vulnerable-to-paraphrasing-attacks-researchers-find/" target=&ldquo;blank&rdquo;>&lt;Vecturebeat&gt;</a> <a href="https://bdtechtalks.com/2019/04/02/ai-nlp-paraphrasing-adversarial-attacks/" target=&ldquo;blank&rdquo;>&lt;Tech Talks&gt;</a> <a href="https://www.jiqizhixin.com/articles/2019-03-27-10?from=synced&amp;keyword=SysML%202019" target=&ldquo;blank&rdquo;>&lt;机器之心&gt;</a>
</p>
</li>
</ul>
<p>1. Rashish Tandon, <b>Qi Lei</b>, Alexandros G. Dimakis, Nikos Karampatziakis, <a href="https://arxiv.org/abs/1612.03301" target=&ldquo;blank&rdquo;>&ldquo;Gradient Coding: Avoiding Stragglers in Distributed Learning&rdquo;</a>, <i>Proc. of International Conference of Machine Learning (ICML), 2017</i> <a href="https://github.com/rashisht1/gradient_coding" target=&ldquo;blank&rdquo;>(code)</a>
</p>
<div id="footer">
<div id="footer-text">
Page generated 2021-05-10 19:50:48 UTC, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
